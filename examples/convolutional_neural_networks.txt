Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
1 
arXiv:1901.06032 [cs.CV]  
 A Survey of the Recent Architectures of Deep Convolutional Neural Networks  
Asifullah Khan1, 2*, Anabia  Sohail1, 2, Umme Zahoora1, and Aqsa Saeed Qureshi1 
1 Pattern Recognition Lab, DCIS, PIEAS, Nilore, Islamabad 45650, Pakistan  
2 Deep Learning Lab, Center for Mathematical Sciences, PIEAS, Nilore, Islamabad 45650, Pakistan  
asif@pieas.edu.pk  
 
 
Abstract  
Deep Convolutional Neural Network (CNN) is a special  type of Neural Networks, which has 
shown exemplary performance on  several competitions related to Computer Vision and Image 
Processing. Some of the exciting application areas of CNN include Image Classification and 
Segmentation, Object Detection, Video Pr ocessing, Natural Language Processing, and Speech 
Recognition. The  powerful learning ability of deep CNN is primarily due to the use of multiple 
feature extraction stages that can automatically learn representations from the data. The 
availability of a lar ge amount of data and improvement in the hardware technology has 
accelerated the research in CNNs, and recently interesting deep CNN architectures have been 
reported. Several inspiring ideas to bring advancements in CNNs have been explored, such as the 
use of different activation and loss functions, parameter optimizatio n, regularization, and 
architectural innovations. However, the significant improvement in the representational capacity 
of the deep CNN is achieved through architectural innovations. Notably , the ideas of exploiting 
spatial and channel information, depth a nd width of architecture, and multi -path information 
processing have gained substantial attention.  Similarly, the idea of using a block of layers as a 
structural unit is also gaining popular ity. This survey thus focuses on the intrinsic taxonomy 
present in  the recently reported deep CNN architectures and, consequently, classifies the recent 
innovations in CNN architectures into seven different categories. These seven categories are 
based on s patial exploitation, depth, multi -path, width, feature -map exploit ation, channel 
boosting, and attention. Additionally, the elementary understanding of CNN components, current 
challenges, and applications of CNN are also provided.  
Keywords:  Deep Learning , Convolutional Neural Network s, Taxonomy , Representational 
Capacity , Residual  Learning, and Channel Boosted CNN .  
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
2 
arXiv:1901.06032 [cs.CV]  
 1 Introduction  
Machine Learning (ML) algorithms are known to learn the underlying relationship in data and 
thus make decisions without requiring explicit instructions.  In literature, various exciting works 
have  been reported to understand and/or emulate the human sensory responses such as speech 
and vision (Hubel and Wiesel 1962, 1968; Ojala et al. 1996; Chapelle 1998; Lowe 1999; Da lal 
and Triggs 2004; Bay et al. 2008; Heikkilä et al. 2009) . In 1989, a new class of Neural Networks 
(NN), called Convolutional Neural Network (CNN) (LeCun et al. 1989)  was reported, which has 
shown enormous potential in Machine Vision (MV) related task s. 
CNNs are one of the best learning algorithms for understanding image con tent and have 
shown exemplary performance in image segmentation, classification, detection, and retrieval 
related tasks (Ciresan et al. 2012; Liu et al. 2019) . The success of CNNs has captured attention 
beyond academia. In industry, companies such as Google, Microso ft, AT&T, NEC, and 
Facebook have developed active research groups for exploring new architectures of CNN (Deng 
et al. 2013) . At present, most of the frontrunners of image processing and computer vision  (CV)  
competitions are employing deep CNN based models.  
The attractive feature of CNN is its ability to exploit spatial or temporal correlation in 
data. The topology of CNN is divided into multiple learning stages composed of a combination 
of the convolutional layers, non -linear processing units, and subsampling layers (Jarrett et al. 
2009) . CNN  is a feedforward multilayered hierarchical network, where each layer, using a bank 
of convoluti onal kernels, performs multiple transformations (LeCun et al. 2010) . Convolution 
operati on helps in the extraction of useful features from locally correlated data points. The output 
of the convolutional kernels is then assigned to the n on-linear processing unit (activation 
function), which not only helps in learning abstractions but also embe ds non -linearity in the 
feature space. This non -linearity generates different patterns of activations for different responses 
and thus facilitates i n learning of semantic differences in images. The output of the non -linear 
activation function is usually fo llowed by subsampling, which helps in summarizing the results 
and also makes the input invariant to geometrical distortions (Scherer et al. 2010; LeCun et al. 
2010) . CNN, with the automatic feat ure extraction ability, reduces the need for a separate feature 
extractor (Najafabadi et al. 2015) . Thus, CNN withou t exhaustive processing can learn good 
internal representation from raw pixels. Notable attributes of CNN ar e hierarchical learning, 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
3 
arXiv:1901.06032 [cs.CV]  
 automatic feature extraction, multi -tasking, and weight sharing (Guo et al. 2016; Liu et al. 2017; 
Abbas et al. 2019) . 
CNN first came to limelight through the work of LeCuN in 1989 for processing of grid -
like topological data (images and  time series data) (LeCun et al. 1989; Ian Goodfellow et al. 
2017) . The architectural design of CNN was inspired by Hubel an d Wiesel’s work and thus 
mostly follows the basic structure of primate’s visual cortex (Hubel and Wiesel 1962, 1968) . 
Different stages of the learning  process in CNN show quite a resemblance to the primate’s 
ventral pathway of the visual cortex (V1 -V2-V3-V4-IT/VTC) (Laskar et al. 2018) . The visual 
cortex of primates first receives input  from the retinotopic area. Whereby, the lateral geniculate 
nucleus performs multi -scale highpass filtering and contrast normalization.  After this, detect ion 
is performed by different regions of the visual cortex categorized as V1, V2, V3, and V4. In fact,  
V1 and V2 regions of the visual cortex are similar to convolutional and subsampling layers. In 
contrast, the inferior temporal region resembles the highe r layers of CNN, which makes an 
inference about the image (Grill -Spector et al. 2018) .  
During training, CNN learns through backpropagation algorithm, by regulating the 
change in weights according to the target. Optimization of an objective function using a 
backpropagation algorithm is similar to the response b ased learning of the human brain . The 
multilayered, hierarchical structure of deep CNN, gives it the ability to extract low, mid, and 
high-level features. High -level features (more abstract features) are a combination of lower and 
mid-level features. The h ierarchical feature extraction a bility of CNN emulates the deep and 
layered learning process of the Neocortex in the human brain, which dynamically learns features 
from the raw data (Bengio 2009) . The popularity of  CNN is primarily due to its hie rarchical 
feature extraction ability.  
Deep architectures often have an advantage over shallow architectures when dealing with 
complex learning problems. The stacking of multiple linear and non -linear processing units in a 
layer-wise fashion provides the ab ility to learn complex representations at different levels of 
abstraction. Consequently, in recognition tasks consisting of hundreds of image categories, deep 
CNNs have shown substantial performance improvement over conventi onal vision -based models 
(Ojala et al. 2002; Dalal and Triggs 2004; Lowe 2004) . The observation that the deep 
architectures can improve the rep resentational capacity of a CNN heightened the use of CNN in 
image classification and segmentation tasks (Krizhevsky et al. 2012) . The availability of big data 
and advancements in hardwar e are also the main reasons for the recent success of deep CNNs. 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
4 
arXiv:1901.06032 [cs.CV]  
 Empirical studies showed that if given enough training data, deep CNNs can learn the invariant 
representations and may achieve human -level performance. In addi tion to its use as a supervised 
learning mechanism, the potential of deep CNNs can also be exploited to extract useful 
representations from a large scale of unlabeled data. Recently, it is shown that different levels of 
features, including both low and hig h-level, can be transferred to a  generic recognition task by 
exploiting the concept of Transfer Learning (TL) (Qiang Yang et al. 2008; Qureshi et al.  2017; 
Qureshi and Khan 2018) . 
From the late 1990s up to 2000, various improvements in CNN learning methodology 
and architecture were performed to make CNN scalable to large, heterogeneous, complex, and 
multiclass problems. Innovations in CNNs include dif ferent aspects such as modificat ion of 
processing units, parameter and hyper -parameter optimization strategies, design patterns and 
connectivity of layers, etc. CNN based applications became prevalent after the exemplary 
performance of AlexNet on the Image Net dataset in 2012 (Krizhevsky et al. 2012) . Significant 
innovations in CNN have been proposed since then and are largely attributed to the restructuring 
of processing units and designin g of new blocks. Zeiler and Fergus (Zeiler and Fergus 2013)  
gave the concept of layer -wise visualization of CNN to improve the understanding of feature 
extraction stages, which shifted the trend towards extraction of features at low spatial resolution 
in deep architecture as performe d in VGG (Simonyan and Zisserman 2015) . Nowadays, most of 
the new architectures are built u pon the principle of simple and homogenous topology, as 
introduced in VGG. Google deep learning group introduced an innovative idea of a split, 
transform and merge, with the corresponding block known as inception block. The inception 
block for the very fir st time gave the concept of branching within a layer, which allows 
abstraction of features at different spatial scales (Szegedy et al. 2015) . In 2015, the concept of 
skip connections introduced by ResNet (He et al. 2015a)  for the training of deep CNNs gained 
popularity. Afterward, this concept was used by most of the succeeding networks, such as 
Inception -ResNet, Wide  ResNet , ResNeXt, etc., (Szegedy et al. 2016a; Zagoruyko and 
Komodakis 2016; Xie et al. 2017) . 
Different architectural designs such as Wide ResNet , Res NeXt, Pyramidal Net, Xception,  
PolyNet, and many others explore the effect of multilevel transformations on CNNs learning 
capacity by introducing cardinality or increasing the width (Zagoruyko and Komodakis 2016; 
Han et al. 2017; Xie et al.  2017; Zhang et al. 2017) . Therefore, the focus of research shifted from 
parameter optimization and connections readjustment towards the improved architectural design 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
5 
arXiv:1901.06032 [cs.CV]  
 of the network. This shift resulted in many new architectural ideas such as channel boos ting, 
spatial and feature -map wise exploitation and attention -based information processing etc., (Wang 
et al. 2017a ; Khan et al. 2018a; Woo et al. 2018) . 
In the past few years, different interesting  surveys are conducted on deep CNNs that 
elaborate on the essential components of CNN and their alternatives. The survey reported in (Gu 
et al. 2018)  reviewed the famous architectures from 20 12-2015 along with their basic 
components. Similarly, there are prominent surveys that discuss different algorithms and 
applications of CNN (LeCun et al. 2010; Najafabadi et al. 2015; Guo et al. 2016; Srini vas et al. 
2016; Liu et al. 2017) . Likewise, the survey presented in (Zhang et al. 2019)  discusses the 
taxonomy of CNNs based on ac celeration techniques. On the other hand, in this survey, we 
discuss the intrinsic taxonomy present in the recent and prominent CNN architectures reported 
from 2012 -2020. T he various CNN architectures discussed in this survey are broadly classified 
into se ven main categories, namely; spatial exploitation, depth, multi -path, width, feature -map 
exploitation, channel boosting, and attention -based CNNs.  
This survey also gives an  insight into the basic structure of CNN as well as its historical 
perspective, pres enting different eras of CNN that trace back from its origin to its latest 
developments and achievements. This survey will help the readers to develop the theoretical 
insig ht into the design principles of CNN and thus may further accelerate the architectur al 
innovations in CNN.  
The rest of the paper is organized in the following order (shown in Fig. 1): Section 1 
develops the systematic understanding of CNN, discusses its re semblance with primate’s visual 
cortex, as well as its contribution to MV. In this regard, Section 2 provides an overview of 
essential CNN components, and Section 3 discusses the architectural evolution of deep CNNs. 
Whereas, Section 4 discusses the recent  innovations in CNN architectures and categorizes CNNs 
into seven broad classe s. Section 5 and 6 shed light on applications of CNNs and current 
challenges, whereas section 7 discusses future work. Finally, the last section concludes.  
 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
6 
arXiv:1901.06032 [cs.CV]  
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 1 Organization of the survey paper showing different sections.  
 
2 Basic CNN c omponents  
Nowadays, CNN is considered as one of the most widely used ML technique, especially in 
vision -related applications. CNN can learn representations from the grid -like data, an d recently it 
has shown substantial performance improvement in various M L applications. A typical block 
diagram of an ML system is shown in Fig. 2. Since CNN possesses both good feature generation 
and discrimination ability, therefore in a typical ML syste m, CNN capabilities are exploited for 
feature generation and classificat ion. 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
7 
arXiv:1901.06032 [cs.CV]  
 A typical CNN architecture generally comprises alternate layers of convolution and 
pooling followed by one or more fully connected layers at the end. In some cases, a fully 
connec ted layer is replaced with a global average pooling layer. In addition t o different mapping 
functions, different regulatory units such as batch normalization and dropout are also 
incorporated to optimize CNN performance (Bouv rie 2006) . The arrangement of CNN 
components plays  a fundamental role in designing new architectures and thus achieving 
enhanced performance. This section briefly discusses the role of these components in a CNN 
architecture.  
2.1 Convolutional  layer  
The convol utional layer is composed of a set of convolutional  kernels where each neuron acts as 
a kernel. However, if the kernel is symmetric, the convolution operation becomes a correlation 
operation (Ian Goodfellow et al. 2017) . Convolutional kernel works by dividing the image into 
small slices,  commonly known as receptive fields. The division of an image into small blocks 
helps in extracting featu re motifs. Kernel convolves with the images using a specific set of 
weights by multiplying its elements with the corresponding elements of the receptiv e field 
(Bouvrie 2006) . Convolution operation can be expressed as follows :      
 
                                            
,( , ) ( , ). ( , )kk
l c l
c x yf p q i x y e u v=                                       (1) 
where, 
( , )ci x y  is an element of the input image tensor 
CI , which is element wise 
multiplied b y 
( , )k
le u v  index of the kth convolutional kernel 
lk  of the lth layer. Whereas output 
feature -map of the kth convolutional operation can be expressed as  
(1,1),..., ( , ),..., ( , )k k k k
l l l l f f p q f P Q=F
. The different m athematical symbols  used are defined in 
Table 1.  
Due to weight sharing ability of convolutional operation, different sets of features within 
an image can be extracted by sliding kernel with the same set of weights on the image and thus 
makes CNN parameter efficient as compa red to the fully connected networks. Convolution 
operation may further be cate gorized into different types based on the type and size of filters, 
type of padding, and the direction of convolution (LeCun et al. 2015) . 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
8 
arXiv:1901.06032 [cs.CV]  
 
 
 
Fig. 2  Basic layout of a typical ML system having several stages.  
 
 
 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
9 
arXiv:1901.06032 [cs.CV]  
 Table 1 Definition of mathematical symbols  
Symbol  Description  
X
 Total 𝑥 coordinates of an image  
x
 𝑥𝑡ℎ coordinate under consideration of an image  
Y
 Total
y coordinates of an image  
y
 
thycoordinate under consideration of an image  
c
 Channel index  
( , )ci x y
 (𝑥,𝑦) element of 
thc channel of an image  
L
 Total number of layers  
l
 Layer num ber 
lK
 Total number of kernels of 
thl  layer  
lk
 Kernel number of  
thl  layer    
U
 Total number of rows of 
thk  kernel 
u
 
thu row under consideration  
V
 Total number of columns of 
thk  kernel  
v
 
thv  column  under consideration  
( , )k
le u v
 
( , )uv  element of 
thk  kernel of 
thl layer  
k
lF
 Input feature matrix for 
thl layer and 
thk neuron  
P
 Total number of rows of feature matrix  
p
 
thprow under consideration  
Q
 Total number of columns of feature matrix  
q
 
thqcolumn  under consideration  
( , )k
lf p q
 
( , )pq element of feature matrix  
(.)cg
 Convolution operation  
(.)pg
 Pooling operation  
(.)ag
 Activation f unction  
(.)kg
 Concatenation operation  
gtg
 Transformation gate  
gcg
 Carry gate  
(.)sqg
 Squeeze operation  
(.)exg
 Excitation operation  
1K
l+Y
 Weight vector showing feature -maps importance learned using SE operation  
tg
 Transformation function for two layer NN implemented by SE block  
gsg
 Sigmoid gate implemented by SE block  
smg
 Soft mask  
tmg
 Trunk mask  
BI
 Channel boosted input tensor  
 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
10 
arXiv:1901.06032 [cs.CV]  
 2.2 Pooling layer  
Feature motifs, which result as an output of convolution operation, can occur at different 
locations in the image. O nce features are extracted, its exact location becomes less important as 
long as its approximate position relative to others is preserved. Pooling or down -sampling is an 
interesting local operation. It sums up similar information in the neighborhood of the  receptive 
field and outputs the dominant response within this local region (Lee et al. 2016) . 
                                                        
()kk
l p lg=ZF                                                        (2) 
Equation (2 ) shows the pooling operation in which 
k
lZ  represents  the pooled feature -map 
of lth layer  for kth input feature -map 
k
lF, where as 
(.)pg  defines the type of pooling operation.  
The use of pooling operation helps to extract a combination of features, which are invariant to 
translational shifts and small distortions (Ranzato et al. 2007; Scherer et al. 2010) . Reduction in 
the size of f eature -map to invariant feature set not only regulates the complexity of the network 
but also helps in increasing the generalization by reducing overfitting. Different types of pooling 
formulations such as max, average, L2, ove rlapping, spatial pyramid poo ling, etc. are used in 
CNN (Boureau 2009; Wang et al. 2012; He et al. 2015b) . 
2.3 Activation f unction  
Activation function  serves as  a decision function and helps in learning of intricate patterns. The 
selection of an appropriate activation function can accelerate the learning process. The activation 
function for a convolved feature -map is defined in equati on (3) .  
                                                          
()kk
l a lg=TF                                                      (3) 
In the above equation,  
k
lF  is an output of a convolution, which is assigned to activat ion 
function  
(.)ag  that adds non -linearity and returns a transformed output 
k
lT  for lth layer. In 
literature , different activation functions such as sigmoid, tanh, maxout , SWISH, ReLU, and 
variants of ReLU , such as leaky ReLU, ELU, and PReLU  are used to inculcate non -linear 
combination of features  (LeCun 2007; Wang et al. 2012; Xu et al. 2015a; Ramachandran et al. 
2017; Gu et al. 2018) . However, ReLU  and its va riants are preferred as they help  in overcoming 
the vanishing gradient problem (Hochreiter 1998; Nwankpa et al. 2018) . One of the recently 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
11 
arXiv:1901.06032 [cs.CV]  
 proposed activation function is MISH , which has shown  better performance  than ReLU  in most 
of the recently proposed deep networks on benchmark datasets  (Misra 2019) .  
2.4 Batc h normalization  
Batch n ormalization  is used to address the issues related to the internal covariance shift  within 
feature -maps. The internal covariance shift is a change  in the distribution  of hidden units’ values, 
which  slow s down the convergence (by forcing learning rate to small value) and requires careful 
initialization of parameters. Batch normalization for  a transformed feature -map 
k
lF  is shown in 
equation (4). 
                                                               
2k
k lB
l
B
−=
+FN                                                      (4) 
In equation (4 ), 
k
lN represents  normalized feature -map,  
k
lF is the input feature -map, 
B
and 
2
B  depict mean and variance  of a feature -map for a mini batch respectively . In order to 
avoid division by zero, 
  is added for numerical stability. Batch norma lization unifies the 
distribution of feature -map values by setting  them to zero mean and unit variance (Ioffe and 
Szegedy 2015) . Furthermore, it smoothen s the flow of gr adient and acts as a regulating  factor, 
which thus helps in  improving the generalization of the network .  
2.5 Dropout  
Dropout introduces  regularization within  the network, which ultimately improves generalization 
by randomly skipping some units or connections with a certai n probability. In NN s, multiple 
connections that learn a non -linear relation are so metimes co -adapted, which cause s overfitting  
(Hinton et al. 2012b) . This random dropping of some connections or units produces several 
thinned network architectu res, and finally , one representative network is selected with small 
weights. Th is selected architecture is then considered as an approximation  of all of the proposed 
networks  (Srivastava et al. 2014) . 
2.6 Fully c onnected  layer  
Fully connected layer is mostly used at the end of the network for classification. Unlike pooling 
and conv olution, it is a global operation . It takes input from feature extraction stages  and 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
12 
arXiv:1901.06032 [cs.CV]  
 globally analyses the output of all the preceding  layers (Lin et al. 2013) . Consequently , it makes 
a non -linear combination of selected features, which are used for the classification of data  
(Rawat and Wang 2016) . 
3 Architectural evolution of deep CNNs  
Nowadays, CNNs are considered as the most w idely used algorithms among biologically 
inspired Artificial Intelligence (AI) techniques. CNN history begins with the neurobiological 
experiments conducted by Hubel and Wiesel (1959, 1962) (Hubel and Wiesel 1959, 1962) . Their 
work provided a platfo rm for many cognitive models, and CNN replaced almost all of these . 
Over the decades,  different  efforts have  been carried out to improve the performance of CNNs. 
The e volutionary history of deep CNN architectures is pictorially represented in Fig. 3. 
Improvements in CNN architectures can be categorized into five different eras that are discussed 
below.  
3.1 Origin of CNN : Late 1980s -1999  
CNNs have been applied to visual tas ks since the late 1980s. In 1989, LeCuN et al. proposed the 
first multilayered CNN named ConvNet, whose origin rooted in Fukushima’s Neocognitron 
(Fukushima and Miyake 1982; Fukushima 1988 ). LeCuN proposed a  supervised training of 
ConvNet using the backpropag ation algorithm , in comparison  to the unsupervised reinforcement 
learning scheme used by its predecessor Neocognitron (Linnainmaa 1970; LeCun et al. 1989) . 
LeCuN’s work thus made a foundation for the modern 2D CNNs. This ConvNet showed 
successful results for handwritten digit and zip code recognition related problems (Zhang  and 
LeCun 2015) . In 1998, LeCuN proposed an improved version of ConvNet, which was famously 
known as LeNet -5, and it started the use of CNN in classifying characters in a document 
recognition related applications  (LeCun et al. 1995, 1998) . Due to the good performance of CNN 
in optical character and fingerprint recognition, its commercial use in ATM and Banks started in 
1993 and 1996, respectively. In this era , LeNet -5 achieved many successful milestones for 
optical character recognition tasks, but it didn’t perform well on other image recognition 
problems.  
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
13 
arXiv:1901.06032 [cs.CV]  
 
 
 
Fig. 3  Evolutionary history of deep CNNs showing architectural  innovations from ConvNet till 
to date architectures.  
 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
14 
arXiv:1901.06032 [cs.CV]  
 3.2 Stagnation of CNN : Early 2000  
In the late 1990s and early 2000 , researchers had  little insight into the internal working of CNN, 
and it was considered as a black box. Complicated  architecture de sign an d heavy processing 
made it hard to train  CNN. It was widely presumed in early 2000  that the backpropagation  
algorithm used for training of CNN was not effective in converging to the global minima of the 
error surface . Thus, CNN was considered as a less effective  feature extractor compared to 
handcrafted  features (Schmidhuber 2007) . Moreover, no comprehensive dataset of diverse 
categories of ima ges was available at that time. Therefore, because of the insignificant 
improvement in CNN  performance at the cost of high computational time, little attention was 
given to explore its role in different applications such as object detection, video surveillance, etc.  
At that time , other statistical methods and  in particular, SVM became more popul ar than CNN 
due to their relatively high performance (Joachims 1998; Decoste and Schölkopf 2002; Liu et al. 
2003) .  
Meanwhile,  a few res earch groups  kept on working with CNN s and tried to optimize its 
performance. In 2003, Simard et al . improved CNN architecture and showed good results 
compared to SVM on a hand digit benchmark dataset;  MNIST  (LeCun et al. 1998; Liu et al. 
2003; Simard et al. 2003; Chellapilla et al. 2006; Deng 2012) . This improvement  in performance 
expedited  the research in CNN s by extending their application ’s beyond  optical character 
recognition  to other script’s character recognition , deployment  in image sensors for face 
detection in video conferencing , and regulation  of street crimes , etc . (Abdulkader 2006; 
Chellapilla et al. 2006; Cir esan et al. 2010) . Likewise, C NN based system s were  industrialized in 
markets for customers ’ tracking  (Garcia and Delakis 2004; Frome et al. 2009; LeCun et al. 
2010) . Moreover, CNN ’s potential in other applications such as medical image segmentation, 
anomaly detection, and robot vision was also explored  (Fasel 2002; Matsugu et al. 2002; Chen et 
al. 2006) .  
3.3 Revival of CNN : 2006 -2011  
Deep CNNs generally have complex architecture and time -intensive training phase that 
sometimes may span over weeks. In early 2000, t here were a few parallel processing techniques 
and limited hardware resources for the training of deep Networks. Training of  a deep CNNs with 
a typical activation function such as sigmoid may suffer from exponential decay and explosion of 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
15 
arXiv:1901.06032 [cs.CV]  
 a gradient. Since  2006, significant efforts have been made to tackle the CNN optimization 
problem. In this regard, several interesting initia lization and training strategies were reported to 
overcome the difficulties encountered in the training of deep CNNs and the learnin g of invariant 
features. Hinton reported the concept of greedy layer -wise pre -training in 2006, which revived 
the research i n deep learning (Hinton et al. 2006; Khan et al. 2018b) . Experimental studies 
showed that both supervised and unsuper vised pre -training could initialize a network in a better 
way than random initialization. Bengio and other researchers proposed that  the sigmoid 
activation function is not suitable for the training of deep architectures with random initialization 
of weight s. This observation started the use of activation functions other than sigmoid such as 
ReLU, tanh etc., (Glorot and Bengio 2010) . The revival of deep learning was o ne of the factors, 
which brought deep CNNs into limelight (Bengio et al.  2007, 2013) . 
 Ranzato  et al. (200 7) used max -pooling instead of subsampling, which showed good 
results by learning invaria nt features (Ranza to et al. 2007; Giusti et al. 2013) . In late 2006, 
researchers started using graphics processing units (GPUs) to accelerate  the training of deep NN 
and CNN architectures (Oh and Jung 2004; Strigl et al. 2010; Cireşan et al. 2011; Nguyen et al. 
2019) . In 2007, NVIDIA launched the CUDA programming platform, which allows exploitation 
of parallel processing capabilitie s of GPU with a greater degree (Nickolls et al. 2008; Lindholm 
et al. 2008) . In essence, the use of GPUs for NN and CNN training and other hardwa re 
improvements were the main factors, which revived the research in CNN (Oh and Jung 2004; 
Ciresan et al. 2018) . In 2010, Fei -Fei Li’s group at  Stanford, estab lished a large database of 
images known as ImageNet, containing millions of annotated images belonging to a large 
number of classes (Russakovsky et al. 2015) . This database was coupled with the annual 
ImageNet Large Scale Visual Recognition Challenge (ILSVRC), where the performance s of 
various mod els have been evaluated and scored (Berg et al. 2010) . Similarly, in the same year, 
Stanford releas ed PASCAL 2010 V OC dataset for object detection. ILSVRC and Neural 
Information Processing Systems Conference (NIPS) are the two platforms that play a dominant 
role in strengthening research and increasing the use of CNN and thus making it popular.  
3.4 Rise of CNN : 2012 -2014  
The availability of extensive training data and hardware advancements are the factors that 
contributed to the advancement in CNN research. But the main driving forces that have 
accelerated the research and give rise to the use of CNNs in image classificati on and recognition 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
16 
arXiv:1901.06032 [cs.CV]  
 tasks are parameter optimization strategies and new architectural ideas (Gu et al. 2018; Sinha et 
al. 2018; Zhang et al. 2019) . The main breakthrough in CNN performance was brough t by 
AlexNet, which showed exemplary performance in 2012 -ILSVRC (reduced error rate from 25.8 
to 16.4) as compared to conventional CV techniques (Krizhevsky et al. 2012) . 
 In this era, several attempts were made to improve the performance of CNN; depth and 
parameter optimization strategies were explored with a significant reduction in computational 
cost. Similarly, different architectural designs were propos ed, whereby each new architecture 
tried to overcome the shortcomings of previously proposed architectures in combination with 
new structural reformulations. With the trend of designing very deep CNNs, it generally 
becomes difficult to independently determi ne filter dimensions, stride, padding, and other hyper -
parameters for each layer. This problem is resolved by designing convolutional layers with a 
fixed topology that can be repeated multiple times. This shifted the trend from custom layer 
design towards modular and uniform layer design. The concept of modularity in CNNs made it 
easy to tailor them for different tasks effortlessly (Simonyan and Zisserman 2015; Amer and 
Maul 2019) . In this connection, a diff erent idea of branching and block within a layer was 
introduced by the Google group (Szegedy et al. 2015) . It should be noted that i n this era, two 
different types of architectures, deep and narrow, as well as deep and wide, were in use.  
3.5 Rapid  increase in  architectural i nnovations and a pplications of  CNN : 2015 -
Present  
The research in CNN is still going on and has a significant potentia l for improvement. It is 
generally observed that the significant improvements in CNN performance occurred from 2015 -
2019. The representational capacity of a CNN usually depends on its depth, and in a sense, an 
enriched feature set  ranging from simple to co mplex abstractions can help in learning complex 
problems. However, the main challenge faced by deep architectures is that of the diminishing 
gradient. Initially, researchers tried to subside this problem by connecting intermediate  layers to 
auxiliary learn ers (Szegedy et al. 2015) . In 2015, the emerging area of research was mainly the 
development of new connections to improve the conve rgence rate of deep CNN architectures. In 
this regard, different ideas such as information gating mechanism across multiple layers, skip 
connections,  and cross -layer channel connectivity was introduced (Srivastava et al. 2015a; He et 
al. 2015a; Huang et  al. 2017) . Different experimental studies showed that state -of-the-art deep 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
17 
arXiv:1901.06032 [cs.CV]  
 architectures such as VGG, ResNet, ResNext, etc. also showed good results for challenging 
recognition and localization problems like semantic and instance -based object segmenta tion, 
scene parsing, scene location, etc. Most of the famous object detection and segmentation 
architecture s such as Single Shot Multibox Detector (SSD), Region -based CNN (R -CNN), Faster 
R-CNN, Mask R -CNN and Fully Convolutional Neural Network (FCN) are bu ilt on the lines of 
ResNet, VGG, Inception, etc. Similarly, many interesting detection algorithms such as F eature 
Pyramid Networks, Cascade R -CNN, Libra R -CNN, etc., modified the architectures as 
mentioned earlier to improve the performance (Lin et al. 2017; Cai and Vasconcelos 2019; Pang 
et al. 2020) . Applications of deep CNN were also extended to image captioning by combining 
these networks w ith recurrent neural network (RNN) and thus showed state -of-the-art results on 
MS COCO -2015 image captioning challenge (Girshick 2015; Long et al. 2015; Ren et al. 2015; 
He et al. 2017; Vinyals et al. 2017) . 
Similarly, in 2016, it was obse rved that the stacking of multiple transformations not only 
depth -wise but also in parallel fashion showed good learning for complex problems  (Zagoruyko 
and Komodakis 2016; Han et al. 2017) . Different researchers used a hybrid of the already 
proposed architectures to improve deep CNN performa nce (Huang et al. 2016a; Szegedy et al. 
2016a; Targ et al. 2016; Yamada et al. 2016; Kuen et al. 2017; Lv et al. 2019) . In 2017, the focus 
of researchers was mainly on designing of generic blocks that can be inserted at any learning 
stage in CNN architectur e to improve the network representation (Hu et al. 2018a) . Designing of 
new blocks is one of the growing areas of research in CNN, where generic blocks are used to 
assign atten tion to spatial and feature -map (channel) information (Wang et al. 2017a; Roy et al. 
2018; Woo et al. 2018) . In 2018, a new idea of channel boosting was introduced by Khan et al. 
(Khan et al. 2018a)  to boost the performance of a CNN by learning distinct featur es as well as 
exploiting the already learned features through the concept of TL . 
However, two main concerns observed with deep and wide architectures are the high 
computational cost and memory requirement. As a result, it is very challenging to deploy stat e-
of-the-art wide and deep CNN models in resource -constrained environments. Conve ntional 
convolution operation requires a huge number of multiplications, which increases the inference 
time and restricts the applicability of CNN to low memory and time const raint applications 
(Shakeel e t al. 2019) . Many real -world applications, such as autonomous vehicles, robotics, 
healthcare, and mobile applications, perform the tasks that need to be carried on computat ionally 
limited platforms in a timely manner. Therefore, different modifications in CNN are performed 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
18 
arXiv:1901.06032 [cs.CV]  
 to make them appropriate for resource -constrained environments. Prominent modifications are 
knowledge distillation, training of small networks, or squeezi ng of pre -trained networks (such as 
pruning, quantization, hashing, Huffman codin g, etc.) (Chen et a l. 2015; Han et al. 2016; Wu et 
al. 2016; Frosst and Hinton 2018) . GoogleNet exploited the idea of small networks, which 
replaces the conventional convolution with point -wise group convolution operation to make it 
computationally efficient. Similarly, S huffleNet used point -wise group convolution but with a 
new idea of channel shuffle that significantly reduces the number of operations without affecting 
the accuracy. In the s ame way, ANTNet proposed a novel architectural block known as 
ANTBlock, which at low computational cost, achieved good performance on benchmark datasets 
(Howard et al. 20 17; Zhang et al. 2018a; Xiong et al. 2019) . 
From 2012 up till now, many improvements have been reported in CNN architectures. As 
regards the architectural advancement of CNNs, recently, the focus of research has been on 
designing of new blocks that can bo ost network representation by exploiting feature -maps or 
manipulating inp ut representation by adding artificial channels. Moreover, along with this, the 
trend is towards the design of lightweight architectures without compromising the performance 
to make C NN applicable for resource constraint hardware.  
 
4 Architectural innovation s in CNN  
Different improvements in CNN architecture have been made from 1989 to date. These 
improvements can be categorized as parameter optimization, regularization, structural 
refor mulation, etc. However, it is observed that the main thrust in CNN perfor mance 
improvement came from the restructuring of processing units and the designing of new blocks. 
Most of the innovations in CNN architectures have been made in relation to depth and  spatial 
exploitation. Depending upon the type of architectural modificat ions, CNNs can be broadly 
categorized into seven different classes, namely; spatial exploitation, depth, multi -path, width, 
feature -map exploitation, channel boosting, and attention -based CNNs. The taxonomy of CNN 
architectures is pictorially represented i n Fig. 4. Architectural details of the state -of-the-art CNN 
models, their parameters, and performance on benchmark datasets are summarized in Table 2. 
On the other hand, different on line resources on deep CNN architectures, vision -related dataset, 
and thei r implementation platforms are mentioned in Table 3. In addition to this, the strengths 
and weaknesses of various architectures based on their category are presented in Table 5a -g. 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
19 
arXiv:1901.06032 [cs.CV]  
 
 
 
 
Fig. 4  Taxonomy of deep CNN architectures showing seven different categories.  
 
4.1 Spatial Exploitation  based CNN s 
CNN s have  a large number of parameters  and hyper -parameters , such as weights, biases, number  
of layers , and processing units ( neurons ), filter size, stride, activation function,  learning rate, etc. 
(Kafi et al. 2015; Shin et al. 2016) . As convolutional operation  consider s the neigh borhood 
(locality ) of input  pixels , therefore  different levels of correlation can be explored  by using 
different  filter  sizes . Different size s of filters encapsulate different levels of granularity; usually,  
small size filters extract fine-graine d and larg e size extract coarse -grained information.  
Consequently,  in early 2000 , researchers exploited spatial filters  to improve performance and 
explored the relation of a spatial filter with  the learning of the network.  Different studies 
conducted in this era sug gested that by the adjustment of filter s, CNN can perform well both on 
coarse  and fine -grained details . 
4.1.1  LeNet  
LeNet was proposed by LeCuN in 1998 (LeCun et al. 1995) . It is famous due to its historical 
importance as it was the first CNN, which showed sta te-of-the-art performance on hand digit 
recognition tasks. It has the ability to classify digits without being affected by small distortions,  
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
20 
arXiv:1901.06032 [cs.CV]  
 Table 2  Performance comparison of the recent architectures of different categories. Top 5 error rate is 
reported for all architectures.  
 
 
  
 
 Archit ecture  
Name  Year  Main contribution  Parameters  Error Rate  Depth  Category  Reference  
LeNet  
 1998  - First popular CNN architecture  0.060 M  [dist]MNIST: 0.8  
MNIST: 0.95  5 Spatial Exploitation  (LeCun et al. 
1995)  
AlexNet  2012  - Deeper and wider than the LeNet  
- Uses Relu, dropout and overlap Pooling  
- GPUs NVIDIA GTX 580  60 M  ImageNet: 16.4  
 8 Spatial Exploitation  (Krizhevsky et al. 
2012)  
ZfNet  2014  -Visualizati on of intermediate layers  60 M  ImageNet: 11.7  8 Spatial Exploitation  (Zeiler and 
Fergus 2013)  
VGG  2014  - Homogenous topology  
- Uses small size kernels  138 M  ImageNet: 7.3  19 Spatial Exploitation  (Simonyan and 
Zisserman 2015)  
GoogLeNet  2015  
 - Introduce d block concept  
- Split transform and merge idea  4 M ImageNet: 6.7  22 Spatial Exploitation  (Szegedy et al. 
2015)  
Inception -V3  2015  - Handles the problem of a representational 
bottleneck  
- Replace large size filters with small filters  23.6 M  ImageNet : 3.5 
Multi -Crop: 3.58  
Single -Crop: 5.6  159 Depth + Width  (Szegedy et al. 
2016b) 
Highway  
Networks  2015  - Introduced an idea of Multi -path  2.3 M  CIFAR -10: 7.76  19 Depth + Multi -Path (Srivasta va et al. 
2015a)  
Inception -V4  2016  - Split transform and merge idea  
Uses asymmetric filters  35 M  ImageNet: 4.01  70 Depth +Width  (Szegedy et al. 
2016a)  
Inception -
ResNet  2016  - Uses split transform merge idea and 
residual links  55.8M  ImageNet: 3.52  
 572 Depth + Width + 
Multi -Path (Szegedy et al. 
2016a)  
ResNet   2016  - Residua l learning  
- Identity mapping based skip connections  25.6 M  
1.7 M  ImageNet: 3.6  
CIFAR -10: 6.43  152 
110  Depth + Multi -Path (He et al. 2015a)  
DelugeNet  2016  - Allows cross layer information flow in 
deep networks  20.2 M  CIFAR -10: 3.76  
CIFAR -100: 19.02  146 Multi -path (Kuen et al. 
2018)  
FractalNet  2016  - Different path lengths are interacting with 
each other without any residual con nection  38.6 M  CIFAR -10: 7.27  
CIFAR -10+: 4.60  
CIFAR -10++: 
4.59 
CIFAR -100: 28.20  
CIFAR -100+: 
22.49  
CIFAR100++: 
21.49  20 
 
 
 
 
40 Multi -Path (Larsson et al. 
2016)  
WideResNet  2016  - Width is increased and depth is decre ased 36.5 M  CIFAR -10: 3.89  
CIFAR -100: 18.85  28 
- Width  (Zagoruyko and 
Komodakis 2016)  
Xception  2017  - Depth wise convolution followed by point 
wise convolution  22.8 M ImageNet: 0.055  126 Width  (Chollet 2017)  
Residual 
Attention  Neural 
Network  2017  - Introduce d an attention mechanism  8.6 M  CIFAR -10: 3.90  
CIFAR -100: 20.4  
ImageNet: 4.8  452 Attention  (Wang et al. 
2017a)  
ResNeXt  2017  - Cardinality  
- Homogeneous topology  
- Grouped convolution  68.1 M  CIFAR -10: 3.58  
CIFAR -100: 17.31  
ImageNet: 4.4  29 
- 
101 Width  (Xie et al. 2017)  
Squeeze & 
Excitation 
Networks  2017  - Models interdependencies between 
feature -maps  27.5 M  ImageNet: 2.3  152 Feature -Map 
Exploitation  (Hu et al. 2018a)  
DenseNet  2017  - Cross -layer information flow  25.6 M  
25.6 M  
15.3 M  
15.3 M  CIFAR -10+: 3.46 
CIFAR100+: 17.18  
CIFAR -10: 5.19  
CIFAR -100: 19.64  190 
190 
250 
250 Multi -Path (Huang et al. 
2017)  
PolyNet  
 2017  - Experimented structural diversity  
- Introduce d Poly Inception module  
- Generalizes residual unit using 
polynomial  compositions  92 M  ImageNet: 
Single:4.25  
Multi:3.45  - 
- Width  (Zhang et al. 
2017)  
PyramidalNet  2017  - Increases width gradually per unit  116.4 M  
27.0 M  
27.0 M  ImageNet: 4.7  
CIFAR -10: 3.48  
CIFAR -100: 17.01  200 
164 
164 Width  (Han et al. 2017)  
Conv olutional 
Block Attention 
Module  
(ResNeXt 101 
(32x4d) + 
CBAM)  2018  - Exploits both spatial and feature -map 
information  48.96 M  ImageNet: 5.59  101 Attention  (Woo et al. 2018)  
Concurrent 
Spatial & 
Channel 
Excitation 
Mechanism  2018  - Spatial attention  
- Feature -map atte ntion  
- Concurrent placement of spatial and 
channel attention  - MALC: 0.12  
Viscer al: 0.09  - Attention  (Roy et al. 2018)  
Channel  Boosted 
CNN  2018  - Boosting of original channels with 
additional information rich generated 
artificial channels  - - - Channel Boosting  (Khan et al. 
2018a)  
Competitive 
Squeeze & 
Excitation 
Network CMPE -
SE-WRN -28 2018  - Residual and identity mappings both are  
used for rescaling the feature -map 
 
 36.92 M  
36.90 M    CIFAR -10: 3.58  
CIFAR -100: 18.47  
 152 
152 Feature -Map 
Exploitation  (Hu et al. 2018b)  
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
21 
arXiv:1901.06032 [cs.CV]  
 Table 3  Different online available resources for deep CNNs.  
Category  Description  Source  
Cloud based Platforms  Online free access to 
GPU and other deep 
learning accelerators  Google Colab: https://colab.research.google.com/notebooks/welcome.ipynb  
Colac : https://cocalc.com/  
Commercial platforms 
offered by world 
leading companies  FloydHub:  https://www.floydhub.com/  
Amazon SageMaker: https://aws.amazon.com/deep -learning/  
Microsoft Azure ML Service s: https://azure.microsoft.com/en -gb/services/machine -
learning/  
Google Cloud: https://cloud .google.com/deep -learning -vm/ 
IBM Watson Studio: https://www.ibm.com/cloud/deep -learning  
Deep Learning Libraries  Deep learning libraries 
that provide built -in 
classes of NNs, fast 
numerical computation 
and automated 
estima tion of gradients 
both for CPU and GPU  Pytorch : https://pytorch.org/  
Tensorflow : https://www.tensorflow.org/  
MatConvNet : http://www.vlfeat.org/matconvnet/  
Keras: https://keras.io/  
Theano : http://deeplearning.net/software/theano/  
Caffe: https://caffe.berkeleyvision.org/  
Julia: https://julialang.org/  
Lecture Series  Online available and 
freely accessible deep 
learning courses  Stanford Lecture Series:  
http://cs231n.stanford.edu/  
Udacity:  
https://www.udacity.com/course/deep -learning -nanodegree --nd101  
https://www.udacity.com/course/deep -learning-pytorch --ud188  
Udemy:  
https://www.udemy.com/course/deep -learning -learn -cnns/  
https://www. udemy.com/course/modern -deep -convolutional -neural -networks/  
https://www.udemy.com/course/advanced -computer -vision/  
https://www.udemy.com/course/deep -learning -convolutional -neural -networks -theano -
tensorflow/  
https://ww w.udemy.com/course/deep -learning -pytorch/  
Coursera:  
https://www.coursera.org/learn/convolutional -neural -networks  
https://www.coursera.org/specializations/deep -learning  
Vision Datasets  Online freely accessible 
datasets of different 
categories of annotated 
images  ImageNet: http://image -net.org/  
COCO: http://cocodataset.org/#home  
Visual Genome: http://visualgenome.org/  
Open images: https:// ai.googleblog.com/2016/09/introducing -open -images -dataset.html  
Places: http://places.csail.mit.edu/index. html 
Youtube -8M: https:// research.google.com/youtube8m/index.html  
CelebA:  http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html   
CIFAR10: https://www.cs.to ronto.edu/~kriz/cifar.html  
Indoor Scene Recognition : http://web.mit.edu/torralba/www/indoor.html  
Computer Vision Datasets: https://c omputervisiononline.com/datasets  
Fashion MNIST:  
https://research.zalando.com/welcome/mission/research -projects/fashion -mnist/  
Deep Learning 
Accelerators  Ener gy and 
computation efficient 
deep learning 
accelerators  NVIDIA: http://nvdla.org/  
FPGA: https://www.intel.com/con tent/www/us/en/artificial -
intelligence/pro grammable/overview.html  
Eyeriss: http://eyeriss.mit.edu/  
Google’s TPU: https://cloud.google.com/tpu/  
 
 
 
 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
22 
arXiv:1901.06032 [cs.CV]  
 rotation, and variation of po sition and scale. LeNet is a feed -forward NN that constitutes of five 
alternating lay ers of convolutional and pooling, followed by two fully connected layers. In early 
2000, GPU was not commonly used to speed up training, and even CPUs were slow (Potluri et 
al. 2011) . The main limitation of traditional multilayere d fully connected NN was that it 
considers each pixel as separate input and applies a transformation on it, which was a substantial 
computational burden, specifically at t hat time (Gardn er and Dorling 1998) . LeNet exploited the 
underlying basis of the image that the n eighboring pixels are correlated to each other and feature 
motifs are distributed across the entire image. Therefore, convolution with learnable parameters 
is an effective  way to extract similar features at multiple locations with few parameters. Learning 
with sharable parameters changed the conventional view of training where each pixel was 
considered as a separate input feature from its neighborhood and ignored the correl ation among 
them. LeNet was the first CNN architecture, which not only reduced the nu mber of parameters 
but was able to learn features from raw pixels automatically.  
4.1.2  AlexNet  
LeNet (LeCun et al. 1995)  though, begin the history of deep CNNs, but at that time, CNN was 
limited to hand digit recognition tasks and didn’t perform well to all cl asses of images. AlexNet 
(Krizhevsky et al. 2012)  is considered as the first deep CNN architecture, which showed 
groundbreaking results for image classific ation and recognition tasks. AlexNet was proposed by 
Krizhevesky et al., which enhanced the learning capacity of the CNN  by making it deeper and by 
applying several parameter optimizations strategies (Krizhevsky et al. 2012) . The basic 
architectural design of AlexNet is show n in Fig. 5. In early 2000, hardware limitations curtailed 
the learning capacity of deep CNN architectures by restricting them to small size. In order to get 
the benefit of the representational capacity of deep CNNs, Alexnet was trained in parallel on two 
NVIDIA GTX 580 GPUs to overcome shortcomings of the hardware.  
In AlexNet, depth was extended from 5 (LeNet) to 8 layers to make CNN app licable for 
diverse categories of images. Despite the fact that generally, depth improves generalization for 
different r esolutions of images but, the main drawback associated with an increase in depth is 
overfitting. To address this challenge, Krizhevesky et al. (2012) exploited the idea of Hinton 
(Dahl et al. 2013; Srivastava et al. 2014) , whereby their algorithm randomly skips some 
transforma tional units during training to enforce the model to learn more robust features. In 
addition to this, ReLU was employed as a non -saturating activation function to improve the 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
23 
arXiv:1901.06032 [cs.CV]  
 
convergence rate by alleviating the problem of vanishing gradient to some extent (Hochreiter 
1998; Nair and Hinton 2010) . Overlapping sub sampling and local response normalization were 
also applied to improve the generalization by reducing overfitting. Other adjustments mad e were 
the use of large size filters (11x11 and 5x5) at the initial layers, compared to previously proposed 
networks. Du e to the efficient learning approach of AlexNet, it has significant importance in the 
new generation of CNNs and has started a new era o f research in the architectural advancements 
of CNNs.  
 
 
 
 
 
Fig. 5  Basic layout o f AlexNet  architecture showing its five convolution and three fully 
connected layers.  
 
4.1.3  ZfNet 
The learning mechanism of CNN, before 2013, was based mainly on hit -and-trial, without 
knowing the exact reason behind the improvement. This lack of understanding limited the 
performance of deep CNNs on complex images. In 2013, Zeiler and Fergus proposed a n 
interesting multilayer Deconvolutional NN (DeconvNet), which got famous as ZfNet (Zeiler and 
Fergus 2013) . ZfNet was developed to visualize network performance quantitatively. The idea of 
the visualization of network  activity was to monitor CNN performance by interpreting neuron’s 
activation. In one of the previous studies, Erhan et al. (2009) exploited the same idea and 
optimized the performance of Deep Belief Networks (DBNs) by visualizing the hidden layers’ 
feature  (Erhan et al. 2009) . Similarly, Le et al. (2011) evaluated the learning of deep 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
24 
arXiv:1901.06032 [cs.CV]  
 unsupervised autoencoder (AE) by visualizing the image c lasses generated by the neurons of last 
layer (Le et al. 2011) . DeconvNet works in the same manner as the forward pass CNN but 
reverses the order of convolutional and pooling operation. This reverse mapping projects the 
output of the convolutional layer back to visually perceptible image patterns, consequently gives 
the neuron -level interpretation of the internal feature representation learned at each layer 
(Simonyan et al. 2013; Grün et al. 2016) .  
The idea of feature visualization proposed by ZfNet was experimentally validated on 
AlexNet using DeconvNet, which showed that only a few neu rons were active. In contrast, other 
neurons were dead (inactive) in the first and second layers of the network. Moreover, it showed 
that the features extracted by the second layer exhibited aliasing artifacts. Based on these 
ﬁndings, Zeiler and Fergus adj usted CNN topology and performed parameter optimization. 
Zeiler an d Fergus maximized the learning of CNN by reducing both the filter size and stride to 
retain the maximum number of features in the ﬁrst two convolutional layers. This readjustment 
in CNN top ology resulted in performance improvement, which suggested that fe atures 
visualization can be used for the identification of design shortcomings and for timely adjustment 
of parameters.  
4.1.4  VGG  
The successful use of CNNs in image recognition tasks has ac celerated the research in 
architectural design. In this regard, Si monyan et al. proposed a simple and effective design 
principle for CNN architectures. Their architecture, named as VGG, was modular in layers 
pattern (Simonyan and Zisserman 2015) . VGG was made 19 layers deep compared to AlexNet 
and ZfNet to simulate the relation of depth with the  representational capacity of the network 
(Krizhevsky et al. 2012; Zeiler and Fergus 2013) . ZfNet , which was a frontline network of 2013 -
ILSVRC competition, suggested that small size filte rs can improve the performance of the 
CNNs. Based on these findings, VGG replaced the 11x11 and 5x5 filters with a stack of 3x3 
filters layer and experimentally demo nstrated that concurrent placement of small size (3x3) 
filters could induce the effect of t he large size filter (5x5 and 7x7). The use of the small size 
filters provides  an additional benefit of low computational complexity by reducing the number of 
parame ters. These findings set a new trend in research to work with smaller size filters in CNN. 
VGG regulates the complexity of a network by placing 1x1 convolutions in between the 
convolutional layers, which, besides, learn a linear combination of the resultan t feature -maps. 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
25 
arXiv:1901.06032 [cs.CV]  
 For the tuning of the network, max -pooling is placed after the convolutiona l layer, while padding 
was performed to maintain the spatial resolution (Ranzato et al. 2007) . VGG showed good 
results both for image classification and localiz ation problems. VGG was at 2nd place in the 
2014 -ILSVRC competition but, got fame due to it s simplicity, homogenous topology, and 
increased depth. The main limitation associated with VGG was the use of 138 million 
parameters, which make it computationally expensive and difficult to deploy it on low resource 
systems.  
4.1.5  GoogleNet  
GoogleNet was  the winner of the 2014 -ILSVRC competition and is also known as Inception -V1. 
The main objective of the GoogleNet architecture was to achieve high accuracy with a re duced 
computational cost (Szegedy et al. 2015) . It introduced the new concept of inception block in 
CNN, whereby it incorporates mul ti-scale convolutional transformations using split, transform 
and merge idea. The architect ure of the inception block is shown in Fig. 6. In GoogleNet, 
conventional convolutional layers are replaced in small blocks similar to the idea of substituting 
each layer with micro NN as proposed in Network in Network (NIN) architecture (Lin et al. 
2013) . This block encapsulates filters of different sizes (1x1, 3x3, and 5x5) to capture spatial 
information at different scales, including both fine and coarse grain  level. The exploitation of the 
idea of split, transform, and merge by GoogleNet, helped in addressing a problem related to the 
learning of diverse types of variations present in the same category of images having different 
resolutions. GoogleNet regulates  the computations by adding a bottleneck layer of 1x1 
convolutional filter, before employing large size kernels. In addition to it, it used sparse 
connections (not all the output feature -maps are connected to all the input feature -maps), to 
overcome the pr oblem of redundant information and reduced cost by omitting feature -maps that 
were not relevant. Furthermore, connection’s density was reduced by using global average 
pooling at the last layer, instead of using a fully connected layer. These parameter tuni ngs caused 
a significant decrease in the number of parameters from 138 million to 4 million parameters. 
Other regulatory factors applied were batch normalization and the use of RmsProp as an 
optimizer (Dauphin et al. 2015) . GoogleNet also introduced the concept of auxiliary learners to 
speed up the convergence rate. However, the main drawback of the GoogleNet was its 
heterogeneous topology that needs to be customized from module to module. Another l imitation 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
26 
arXiv:1901.06032 [cs.CV]  
 
of GoogleNet was a representation bottleneck that drastically reduces the feature space in the 
next layer and thus sometimes may lead to loss of useful information.  
 
 
 
 
 
 
 
 
Fig. 6  Basic architecture of the inception block showing the split, transform , and merge concept.  
 
4.2 Depth based CNNs  
Deep CNN architectures are based on the assumption that with  the increase in depth, the network 
can better approximate the target function with a number of nonlinear mappings and more 
enriched feature hierarchies (Bengio 2013) . Network depth has played an essential role in the 
success of supervised training. Theoretical studies have shown that deep networks can represent 
certain classes of function more efficiently than shallow architectures (Montufar et al. 2014) . 
Csáji represented a universal approximation theorem in 2001, which states that a single hidden 
layer is sufficient to approximate any function. However, this comes at the cost  of exponentially 
many neurons; thus, it often makes it computationally non -realistic (Csáji 2001) . In this regard, 
Bengio and Delalleau (Delalleau and Bengio 2011)  suggested that deeper networks can maintain 
the expressive power of the network at a reduced cost (Wang and Raj 2017) . In 2013, Bengio et 
al. empirically showed that deep networks are computationally more eff icient for complex tasks 
(Bengio et al. 2013; Nguyen et al. 2018) . Inception and VGG, which showed the best 
performance in 2014 -ILSVRC competition, further strengthen the idea that the depth is an 
essential dimension in regulating learning capacity of the networks (Simonyan and Zisserman 
2015; Szegedy et al. 2015, 2016a, b) . 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
27 
arXiv:1901.06032 [cs.CV]  
 4.2.1  Highway Networks  
Based on the intuition that the learning capacity can be improved by increasing the network 
depth, Srivastava et al. in 2015, proposed a deep  CNN, named as Highway Networks (Srivastava 
et al. 2015a) . The main problem concerned with deep networks is slow trai ning and convergence 
speed (Huang et al. 2016b) . Highway Networks exploited depth for learning enriched feature 
representat ion and introducing a new cross -layer connectivity mechanism (discussed in Section 
4.3.1) for the successful traini ng of the deep networks. Therefore, Highway Networks are also 
categorized as multi -path based CNN architectures. Highway Networks with 50 -layers showed a 
better convergence rate than thin but deep architectures (Berg et al. 2010; Morar et al. 2012) . 
Srivastava et al. experimentally showed that  the performance of a plain network decreases after 
adding hidden units beyond 10 layers (Glorot and Bengio 2010) . Highway Networks, on the 
other hand, was shown to converge  signiﬁcantly faster than the plain ones, even with the depth of 
900 layers.  
4.2.2  ResNet  
ResNet was proposed by He  et al., which is considered as a continuation of deep networks (He et 
al. 2015a) . ResNet revolutionized the CNN architectural race by introducing the conc ept of 
residual learning in CNNs and devised an efficient methodology for the training of deep 
networks. Similar to  Highway Networks, it is also placed under the Multi -Path based CNNs; 
thus, its learning methodology is discussed in Section 4.3.2. ResNet pr oposed 152 -layers deep 
CNN, which won the 2015 -ILSVRC competition. The architecture of the residual block of 
ResNet  is shown in Fig. 7. ResNet, which was 20 and 8 times deeper than AlexNet and VGG, 
respectively, showed less computational complexity than pr eviously proposed networks 
(Krizhevsky et al. 2012; Simonyan and Zisserman 2015) . He et al. empirically showed  that 
ResNet with 50/101/152 layers has less error on image classification task than 34 layers plain 
Net. Moreover, ResNet gained a 28% impro vement on the famous image recognition benchmark 
dataset named COCO (Lin et al. 2014) . Good performance of ResNet on image recognition and 
localization tasks showed that repr esentational depth is of central importance for many visual 
recognition tasks.  
 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
28 
arXiv:1901.06032 [cs.CV]  
 
 
 
 
 
 
 
 
 
 
Fig. 7  Residual block as a basic structural un it of ResNet.   
 
4.2.3  Inception -V3, V4 and Inception -ResNet  
Inception -V3, V4 and Inception -ResNet, are improved versions of Inception -V1 and V2 
(Szegedy et al. 2015, 2016a, b) . The idea of Inception -V3 was to reduce the computational cost 
of deep networks without affecting the generalization. For this purpose, Szegedy et al. replaced 
large size filters (5x5 and 7x7) with small and asymmet ric filters (1x7 and 1x5) and used 1x1 
convolution as a bottleneck before the large filters (Szegedy et al . 2016b) . Concurrent placement 
of 1x1 convolution with a large size filter makes the traditional convolution operation more like 
a cross -channel correlation. In one of the previous works, Lin et al. exploited the potential of  1x1 
filters in NIN architectu re (Lin et al. 2013) . Szegedy et al. (Szegedy et al. 2016b)  intelligently 
used the same concept. In Inception -V3, 1x1 convolutional operation was used, which maps the 
input data into 3 or 4 separate spaces  that are smaller than the ori ginal input space, and then 
maps all correlations in these smaller 3D spaces, via regular (3x3 or 5x5) convolutions. In 
Inception -ResNet, Szegedy et al. combined the power of residual learning and inception block 
(He et al. 2015a; Szegedy et al. 2016a) . In doing so, filter concatenation was replaced by the 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
29 
arXiv:1901.06032 [cs.CV]  
 residual connection. Moreover, Szegedy et al. experimentally showed that Inception -V4 with 
residual co nnections (Inception -ResNet) h as the same generalization power as plain Inception -
V4 but with increased depth and width. However, they observed that Inception -ResNet 
converges more quickly than Inception -V4, which depicts that training with residual connec tions 
accelerates the training  of Inception networks significantly.  
4.3 Multi -Path  based CNNs  
Training of deep networks is a challenging task, and this has been the subject of recent research 
on deep networks.  Deep CNNs generally perform well on complex tasks. However, they may 
suffer from performance degradation, gradient vanishing, or explosion problems, which are not 
caused by overfitting but instead by an increase in the depth (Hochreiter 1998; Dong et al. 2016) . 
Vanishing gradient problem not only results in higher test error but also higher training error 
(Pascanu et al. 2012; Dong et al. 2016; Dauphin et al. 20 17). For training deep networks, the 
concept of multi -path or cross -layer connectivit y was proposed (Srivastava et al. 2015a; Larsson 
et al. 2016; Huang et al. 2017; K uen et al. 2018) . Multiple paths or shortcut connections can 
systematically connect o ne layer to another by skipping some intermediate layers to allow the 
specialized flow of information across the layers (Mao et al. 2016; Tong et al. 2017) . Cross -layer 
connectivity partitions the network into several blocks. These paths also try to solve the 
vanis hing gradient problem by making gradient accessible to lower layers. For this purpose, 
different types of shortcut connections are used, such as zero -padded, projection -based, dropout, 
skip connections, and 1x1 connections, etc.  
4.3.1  Highway Networks  
The increase in depth of a network improves performance mostly for complex problems, but it 
also makes training of the network difficult. In deep networks, due to a large number of layers, 
the backpropagation of error may result  in small gradient values at low er layers. To solve this 
problem, in 2015, a new CNN architecture named Highway Networks  was proposed based on the 
idea of cross -layer connectivity (Srivastava et al. 2015a) . In Highway Networks, the unimp eded 
flow of information across layers is enabled by imparting two gating units within a layer 
(equation (5)). The idea of a gating mechanism was inspired by Long Short  Term Memory 
(LSTM) based on Recurrent Neural Networks (RNN) (Mikolov et al. 2010; Sundermeyer et al. 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
30 
arXiv:1901.06032 [cs.CV]  
 2012) . The aggregation of information by combining the 
thl  layer and previous  
lj−  layers 
information creates a regularizing effect, making gradient -based training of very deep networks 
easy. This cross -layer connectivity enables the training of a network with more than 100 layers, 
even as deep as 900 layers wit h a stochastic gradie nt descent algorithm. Cross -layer connectivity 
for Highway Network is defined in equation (5 & 6).  
 
                                                
1 ( , ). ( , ). ( , )gg
ggtc k k k k
l c l l t l l c l g g g+=l F F k F k F k                        (5) 
                                           
( , ) 1 ( , )gg
ggctkk
c l l t l lgg =− F k F k                                     (6) 
In equation (5 ), 
( , )k
c l lgFk  represents the working of the lth hidden layer , whereas 
gt  and 
gc
 are two gates that decide  the flow of  inform ation across the layers. When 
gt  gate is open , 
gt = 1
 then transformed input is assigned to the next layer. Whereas, when the value of 
gt = 0  
then 
gc  gate establishes  an effect of information highway and input 
k
lF  of lth layer is directly 
assigned to the next layer  l+1 without any transformation . 
4.3.2  ResNet  
In order t o address the problem s faced during training of dee p networks , ResNet  exploited the 
idea of bypass pathways used in Highway Networks  (He et al. 2015a) . Mathem atical f ormulation  
of ResNet is expressed in equation s (7, 8 & 9). 
                                         
'
1 ( , )k k k
m c l m l m l g m l+ → →= + F F k F                                    (7) 
                                                  
'
11 ()kk
m a m g++=FF                                                    (8) 
                                          
'
1 ( , )k k k
c l m l m m lg→ → +=− F k F F                                                 (9) 
where,  
( , )k
c l m l mg→→Fk is a transformed signal , and 
k
lF is an input  of lth layer . In equation 
(7), 
lm→k  shows the kth processing unit (kernel), whereas 
lm→  suggests that the residual block 
can be consis ts of one or more than one hidden layer s. Original input 
k
lF  is added to transformed 
signal (
( , )k
c l m l mg→→Fk ) through bypass pathway ( equation (7)) and thus results  in an aggregated 
output  
'
1k
m+F , which  is assigned to the next layer  after applying activation function  
(.)ag . 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
31 
arXiv:1901.06032 [cs.CV]  
 Whereas , 
'
1()kk
ml+−FF , returns a  residual information , which is used to perform reference based 
optimization  of weights . The distin ct feature of Res Net is reference based residual l earning 
framework . ResNet suggested that residual functions are easy to optimize and can gain accuracy 
for considerably increased depth.  
ResNet introduced shortcut connec tions within layers to enable cross -layer connectivi ty; 
however, these connections are data -independent and parameter -free in comparison to the gates 
of Highway Networks. In Highway Networks, when a gated shortcut is closed, the layers 
represent non -residu al functions. However, in ResNet, residual informati on is always passed, and 
identity shortcuts are never closed. Residual links (shortcut connections) speed up the 
convergence of deep networks, thus giving ResNet the ability to avoid gradient diminishing 
problems.  
 
4.3.3  DenseNet  
Similar to Highway Network s and ResNet, DenseNet was proposed to solve the vanishing 
gradient problem (Srivastava et al. 2015a; He et al. 2015a; Huang et al. 2017) . The problem with 
ResNet  was that it explicitly preserves information through additive identity transformations due 
to which many layers may contribute very little or no information. To address this problem, 
DenseNet us ed cross -layer connectivity but, in a modified fashion. Dense Net connected each 
preceding layer to the next coming layer in a feed -forward fashion; thus, feature -maps of all 
previous layers were used as inputs into all subsequent layers as expressed in equ ation (10 & 11).    
                                                         
21 ( , )k
cCgI=Fk                                                      (10) 
                                                     
11( ,..., )k k k
l k lg− =F F F                                                   (11) 
where 
2kF  and 
k
lF  are the resultant feature -maps of 1st and l-1th transformation layer s and 
(.)kg
 is a function , which  enables cross -layer connectivit y by concatenating proceeding layers 
information before assigning to new transformation layer  l. This establishes  
( 1)
2ll+  direct 
connections in  DenseNet,  as compared  to 
l connections between a layer and its prece ding layer  
in the traditional CNNs . It imprints the effect of cross -layer depth wise convolutions. As 
DenseNet concatenates the features of the previous layer instead of adding them , thus, the 
network  may gain the ability  to explicitly differentiate between  information that is added to the 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
32 
arXiv:1901.06032 [cs.CV]  
 network and information that is preserved. DenseNet  has a narrow layer structure;  however , it 
become s parametrically expensive with an increase  in a number  of feature -maps.  Information 
flow in the network improves by provi ding each layer direct access to the gradients through the 
loss function. Direct admittance to gradient incorporates a regularizing effect, which reduces 
overfitting on tasks with smaller training sets.                                         
4.4 Width bas ed Multi -Connection CNNs  
During 2012 -2015, the focus  was mainly  on exploiting the power  of depth , along with the 
effectiveness  of multi -pass regulatory connections in network regularization  (Srivastava et al. 
2015a; He et al. 2015a) . However,  Kawaguchi et al. reported that  the width of the network  is also 
important (Kawaguchi et al. 2019) . Multilayer perceptron gained the advantage of mapping 
complex functions over perceptron by making parallel use of m ultiple processing units within a 
layer. This suggests  that width is an essential  parameter in defining principles of learning along 
with depth. Lu et al. (2017), and Hanin and Sellke  (2017) have recently shown that NNs with 
ReLU activation fun ction have t o be wide enough to hold universal approximation propert y 
along with  an increase  in depth  (Hanin and Sellke 2017) . Moreover,  a class of continuous 
functions on a compact set cannot be arb itrarily well approximated by an arbitrarily deep 
network , if the maximum width of the network is not larger than the input dimension  (Lu et al. 
2017b; Nguyen et al. 2018) . Although , stacking of multiple layers (increasing depth) may learn 
diverse feature representations , but may not necessarily increase the learning  power of the NN. 
One major problem linked with deep a rchitecture s is that some layers or processing units may 
not learn useful features. To tackle this problem, the focus of research shifted from deep and 
narrow  architectu re towards  thin and  wide architectures.  
4.4.1  Wide  ResNet  
It is concerned that t he main drawback associated with deep residual networks is the feature 
reuse problem in which some feature transformations  or blocks may contribute very little to 
learning  (Srivastava et al. 2015b) . This problem was addressed by Wide ResNet  (Zagoruyko and 
Komodakis 2016) . Zagoruyko  and Komodakis  suggested that  the main learning potential of deep 
residual networks is due to  the residual units, whereas depth has a supplement ary effect. Wide 
ResNet  exploited  the power  of the residual blocks by making ResNet wide rather than deep  (He 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
33 
arXiv:1901.06032 [cs.CV]  
 et al. 2015a) . Wide ResNet  increase d the width by introducing an additional factor k, which 
controls the width of the network . Wide ResNet  show ed that the widening of  the layers  might  
provide  a more effective way of  a performance  improvement  than by making  the residual 
networks deep .  
Deep  network s improve d representational capacity , but they have  some demerits such as  
time-intensive  training , feature reuse , and gradient van ishing and exploding problem . He et al.  
address ed feature reuse problem by incorporating dropout in residual blocks to regularize 
network effectively (He et al. 2015a) . Similarly, Huang et al . introduce d the concep t of stochastic 
depth by exploiting dropouts to solve vanishing gradient and slow learning problem s (Huang et 
al. 2016a) . It was observed that even fraction improvement in performance might  requir e the 
addition  of many new layers. However, Zagoruyko  and Komodakis (2016), empirical ly showed 
that though  Wide  ResNet  was twice in a number of  parameters  as compared to  ResNet , but can 
be trained in a better way than the deep networks  (Zagoruyko and K omodakis 2016) . Wide  
ResNet was based on the observation  that almost all architectures before residual network s, 
including the most success ful Inception and VGG, were  wide  as compared to ResNet. In Wide  
ResNet, learning is made effective by adding a dropo ut in between the convolutional layer s 
rather than inside a residual  block . 
4.4.2  Pyramid al Net 
In earlier deep CNN architectures  such as AlexNet, VGG , and ResNet, due to  the deep stacking 
of multiple convolutional layers , depth  of feature -maps increases  in subsequent layers . However, 
the spatial dimension decreases , as each convolutional layer or block is followed by a sub-
sampling  layer (Krizhevsky et al. 2012; Simonyan and Zisserman 2015; He et al. 2015a) . 
Therefore, Han et al. argued that in deep CNNs , a drastic incr ease in the feature -map depth and, 
at the same time , the loss of spatial information  limits the  learning ability  of CNN  (Han et al. 
2017) . ResNet  has shown remarkable results for image classification problem s. However , in 
ResNet , the deletion of a residual  block , where the dimension of both spatial and feature -map 
(channel)  varies (feature -map depth increases , while spatial dimension decreases ), generally 
deteriorates performance.  In this regard, s tochastic ResNet  improved the  performance by 
reducing information loss asso ciated with the dropping  of the residual  unit (Huang et al. 2016a) . 
To increase the learning ability of ResNet , Han et al.  proposed  the Pyramidal Net (Han et al. 
2017) . In contrast  to drastic  decrease in spatial width with an increase  in depth  by ResNet , 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
34 
arXiv:1901.06032 [cs.CV]  
 Pyramid al Net increase s the width gradual ly per residual unit. This strategy enables pyramidal 
Net to  cover all possible locations instead of maintaining the same spatial dimension within each 
residual block  until down -sampling occurs . Because of a gradu al increase  in the depth of features 
map in a top -down  fashion , it was named  as pyramid al Net . In pyramidal network , depth of 
feature -maps is regulated by factor
l , and is computed using equation ( 12).  
                                              
116 1,
21l
lif l
dd if l nn
−= 
=+   +                                           (12) 
where, 
ld  denotes  the dimen sions of 
thl  residual block  and 
n describes the  number of the 
residual  block , where as  
 is a step size and 
n regulate s the increase  in depth. The depth 
regulating factor tries to distribute the burden of increase  in depth of feature -maps. Residual 
connections were inserted in between the layers by using zero-padde d identity mapping. The 
advantage  of zero-padded  identity mapping is that it needs less number of parameter s as 
compared to the projection -based shortcu t connection, hence may result in better generalization  
(Wang et al. 2019) . Pyramidal Net uses two different approaches for  the widening  of the 
network , including addition  and multiplication based widening. The difference between the two 
types of widening is that  additive pyramidal structure  increases linearly , whereas  multiplicative  
one increases geometrically (Ioffe and Szegedy 2015; Xu et  al. 2015a) . However,  a major 
problem with Pyramidal Net is that with the increase in width , a quadratic times increase in both 
space and time  occurs . 
4.4.3  Xception  
Xception  can be considered as  an extreme I nception architecture, which exploits  the idea  of 
depthwise separable convolution (Chollet 2017) . Xception modified the original inception block 
by making it wider and replacing  the different spatial dimensions (1x1, 5x5, 3x3) with a single  
dimension (3x3)  followed by a 1x1 convolution to regulate computational comp lexity .  
The Architecture of the Xception block is shown in Fig.  8. Xception makes  the network  
computationally efficient by decoupling spatial and feature -map ( channel ) correlation , which is 
math emat ically expressed in equation (13 & 14 ). It works by first  mapping  the convolved outp ut  
 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
35 
arXiv:1901.06032 [cs.CV]  
 
 
 
Fig. 8 Xception building block and its n sets of transformation.  
 
to low dimensional embeddings  using 1x1 convolution s. It then spatially transform s it n times, 
where n is a width defining cardinality , which determines  the number of transformations.  
                                              
1
,( , ) ( , ). ( , )k k k
l l l
xyf p q f x y e u v+=                                        (13) 
                                                        
2 1 1 ( , )kk
l c l l g+ + +=F F k                                                 (14) 
In equation (14 ), 
lk is a kth kernel  of lth layer  having  depth one, which  is spatially 
convolve d across kth feature -map 
k
lF , where 
( , )xy  and 
( , )uv show the spatial indices of feature -
map and kernel respectively . In depthwise  separable convolution, it is to be note d that number of 
kernels 
K  is equal  to number of input feature -maps  contrary  to conventional convolutional layer 
where number of kernels are independent of previous layer feature -maps.  Where as 
1l+k  is kth 
kernel of (1x1) spatial dimension  for l+1th layer , which perfor ms depthwise convolution across  
output feature -maps 
1
111[ ,..., ,..., ]kK
lll+++FFF   of lth layer , used as input of l+1th  layer .  
Xception  makes compu tation easy by separately convolving each feature -map across 
spatial axes, which is followed by pointwise  convolution (1x1 convolutions) to perform cross -
channel  correlation . In conventional CNN architectures;  convolutional operation uses only one 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
36 
arXiv:1901.06032 [cs.CV]  
 transfor mation segment, inception block uses three transformation segment s, whereas in 
Xception number of transformation segment s is equal to the number  of feature -maps . Although 
the transformation strategy adopted by Xception  does not reduce  the number of paramet ers, it 
makes  learning more efficient and  results  in improved performance.  
4.4.4  ResNeXt  
ResNeXt , also known as Aggregated Residual Transform Network, is an improvement over the 
Inception Network (Xie et al. 2017) . Xie et al. exploited the concept of the split, transform , and 
merge in a powerful but simple way by introd ucing a new term; cardinality (Szegedy et al. 
2015) . Cardinality is an additional dimension, which refers to the size of the set of 
transformations (Han et al. 2018; Sharma and Muttoo 2018) . The Inception netw ork has not only 
improved the learning capability of conventional CNNs , but it also makes a network resource -
efficient . However, due to the use of diverse spat ial embedding’s (such as the use of 3x3, 5x5 , 
and 1x1 filter) in the transformation branch, each layer needs to be customized separately. 
ResNeXt  utilized the deep homogenous topology of VGG and simplified GoogleNet architecture 
by fixing spatial resolutio n to 3x3 filters within the split, transform , and merge block. Whereas, it 
used residual learning to improve the convergence of deep and wide network (Simonyan and 
Zisserman 2015; Szegedy et al. 2015; He et al. 2015a) . The b uilding block for ResNe Xt is shown 
in Fig. 9. ResNeXt  used multiple transformations within a split, transform and merge block and 
defined these transformations in terms of cardinality. Xie et al. (2017) showed that an increase in 
cardinality significantly improves performance. T he complexity of ResNeXt  was regulated by 
applying low embedding’s (1x1 fi lters) before 3x3 convolution, w hereas training was optimized 
by using skip connections (Larsson et al. 2016) .  
4.4.5  Inception Family  
Inception family of CNN s also comes under the class of width based m ethods (Szegedy et al. 
2015, 2016a, b) . In Inception networks, within a layer, varying sizes of the filters were used , 
which increased the output of the intermediate layers. The use o f the different sizes of filters 
helps capture the diversity in high -level features. Salient characteristics of the Inception family 
are discuss ed in section 4.1.5 and 4.2.3.  
 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
37 
arXiv:1901.06032 [cs.CV]  
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 9 ResNeXt  building block showing the different paths of transformation.  
 
4.5 Feature -Map (Channel FMap) Exploitation based CNNs  
CNN became popular for MV tasks because of its hierarchical learning and automatic feature 
extraction ability  (LeCun et al. 2010) . Feature  selection  plays a vital role in determining the 
performance  of classification, segmentation, and detection modules. In CNN , features are 
dynamically s elected  by tuning the weights associated with a kernel also known as mask . Also, 
multiple stages of feature extraction are used, which can extract diverse  types of features (known 
as feature -maps or channels  in CNN ). However, som e of the f eature -maps impart little or no role 
in object discrimination  (Hu et al. 2018a) . Enormous feature set s may create  an effect of noise 
and thus lead  to over-fitting of the network . This suggests that a part from network engineering , 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
38 
arXiv:1901.06032 [cs.CV]  
 selection of feature -maps can play an important role in improving  the gener alization of the 
network. In this section, feature -maps and channels will be interchangeably used as many 
researchers have used th e word channels for the feature -maps. 
4.5.1  Squeeze and Excitation Network  
Squeeze and Excitation N etwork (SE-Network) was reported by Hu et al.  (Hu et al. 2018a) . They 
proposed a new b lock for the selection of feature -maps (commonly known as channel s) relevant 
to object discrimination. This new block was named as  SE-block  (shown in Fig.  10), which 
suppresses the less important feature -maps , but  gives high weightage to  the class specifyi ng 
feature -maps . SE-Network reported a record decrease in error on the ImageNet dataset.  SE-block 
is a processing unit that is design ed generically and therefore , can be added in any CNN 
architecture before the convolution la yer. The working of this block consists of  two operations; 
squeeze and excitation. Convolution kernel captu res information locally, but it  ignores the 
contextual relation of features (correlation) that are outside of this receptive field  (LeCun et al. 
2015) . Squeeze operation is performed to get a global view of  feature -maps. The  squeeze block 
generates feature -map wise statistics (also known as feature -map motifs  or descriptors ) by 
suppressing spatial information of the convol ved input. As g lobal average pooling  has the 
potential to learn  the extent of target object effectively  (Lin et al. 2013; Zhou et al. 2016) , 
there fore, it is employed by the squeeze operation  
(.)sqg  using the following equation  (15): 
                                                       
,1( ) ( , )k k k
l sq l l
pqs g f p qPQ== F                              (15) 
where,  
k
ls represents a feature  descriptor  for kth feature -map of lth layer , and  
PQ
defines the spatial dimension  of feature -map 
k
lF . Whereas output of squeeze operation  
1,...,KK
l l l ss=S
 for K number of convol ved feature -maps  for lth layer is assigned to the 
excitation operation  
(.)exg , which models motif -wise interdependencies by exploiting gating 
mechanism. Excitation operation  assigns weights to feature -maps using  two layer feed forward 
NN, which is mathematically expressed in equation (16 ).                                                 
                                                 
1 2 1 ( ) ( , ( , ))
gk k k
l ex l s t ly g g g+== S w S w                               (16) 
In equation (16 ), 
1k
ly+ denotes weig htage  for input feature -map 
1k
l+F of next layer  (l +1), 
where  
(.)tg  and 
(.)
gsg  apply  the ReLU  based non -linear transformation  and sigmoid gate, 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
39 
arXiv:1901.06032 [cs.CV]  
 
respectively.  Similarly, 
1
1 1 1 ,...,KK
l l l yy+ + +=Y  show s the weightage  for K number of convolved 
feature -maps  that are used to rescale them before assigning to the  l+1th layer. In excitation 
operation, 
1w and 
2w  both are used as transformation weight vector s and regulating  factor s to 
limit the model complexity and aid the generalization  (LeCun 2007; Xu et al. 2015a) . The output 
of the first hidden trans formation in NN  is preceded by the ReLU activation function, which 
inculcate s non-linearity  in motif response s. The g ating mechanism is exploited  in SE-block using 
the sigmoid activation function, which models the non -linear responses  of the  feature -maps and 
assigns a weight  based on feature -map relevance  (Zheng et al. 2017) . SE-block adaptively 
recalibrates the feature -maps of each layer by multiplying convolved input  with the motif 
responses .   
 
 
Fig. 10 Squeeze and Excitation block showing the computation of m asks for the recalibration of 
feature -maps that are commonly known as channels in literature.  
 
4.5.2  Competitive Squeeze and Excitation Networks   
Competitive Inner -Imaging Squeeze and Excitation for Residual Network also known as CMPE -
SE Network was pr oposed by Hu et al. in 2018 (Hu et al. 2018b) . Hu et al. used the idea of SE -
block to improve the learning of deep residual networks  (Hu et al. 2018a) . SE -Network 
recalibrates the feature -maps based upon their contribution in class discrimination. However, the 
main concern with SE -Net is that in ResNet , it only considers the residual information for 
determining the weight of each feature -map (Hu et al. 2018a) . This minimizes the impact of SE -
block an d makes ResNet information redundant. Hu et al. a ddressed this problem by generating 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
40 
arXiv:1901.06032 [cs.CV]  
 feature -map wise motifs ( statistics ) from both residual and  identity mapping based feature -maps . 
In this regard, g lobal representation of feature -maps is generated using g lobal average pooling 
operatio n (equa tion (17 )), whereas relevance of feature -maps is estimated by establishing  
competition between feature descriptors  of residual and identity mappings . This phenomena is 
termed as inner imaging (Hu et al. 2018b) . CMPE -SE block not only models the relati onship 
between residual feature -maps but also ma ps their relation with identity feature -map. The 
mathematical expression for CMPE -SE block is represented using the following equation:  
                                                        
'
11, ( ), ( )k k k k
l m sq l sq m gg++= S S F F                                     (17) 
                                                          
11 ( ( , ))k k k
m ex k l m gg++= Y S S                                          (18) 
                                                              
'
1 1 1 .k k k
m m m+ + +=F Y F                                                   (19) 
where 
K
lF  and 
'
1K
m+F  are the identity and residual mapping of input  
K
lF respectively . SE 
block is implemented by applying squeeze operation 
(.)sqg  both on residual and the identity 
feature -maps  and their receptive output is used as joint input of excitation  operation  
(.)exg . 
Where as 
(.)kg represents the concatenation operation.  The output masks  of excitation oper ation 
(equation (18))  are multiplied with residual information (equation (19 )) to rebuild each feature -
map importance . The backpropagation algorithm  thus tries to  optimize  the competition betwee n 
identity and residual feature -maps and the r elationship betw een all feature -maps in the residual  
block.  
4.6 Channel (Input ) Exploitation based CNNs  
Image representation plays an important role in determining the performance of the image 
processing  algorithm s, including both conventional and deep learning algorithms . A good 
representation of the image  is one that can define the salient features of an i mage from a compact 
code. In MV tasks , various types of conventional filters are applied to extract different levels o f 
information for a single type of image  (Lowe 2004; Dollár et al. 2009) . These diverse 
representations are then used as an input of the model  to improve performance  (Do and Ve tterli 
2005 ; Oquab et al. 2014) . Now CNN is a compelling feature learner that can automatically 
extract discriminating feature s depending upon the problem  (Yang et al. 2019) . However, the 
learning of CNN relies on input representation. The lack of diversity and the absence of class 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
41 
arXiv:1901.06032 [cs.CV]  
 discernable  information in the input  may affect  CNN ’s performance as a discriminator . For t his 
purpose, the concept of channel boosting (input channel dimension) using auxiliary learners is 
introduced in CNN s to boost the representation of the network  (Khan et al. 2018a) .  
4.6.1  Channel B oosted CNN using TL  
In 2018, Khan et al. proposed a new CNN architecture  named as Channel boosted CNN  (CB-
CNN )based on the idea of boosting the number of input channels for improving the 
representational  capacity of the network  (Khan et al. 2018a) . The Block diagra m of CB -CNN is 
shown in Fig.  11. Channel boosting is performed by artificially creating extra channels  (known 
as aux iliary channels)  through  auxiliary deep generative models and then exploiting it through 
the deep discriminative models. CB-CNN is mathematically expressed in equation (20 & 21). 
                                                     
1 ( , ,..., )B k C Mg=I I A A                                       (20) 
                                                            
( , )k
l c B lg=F I k                                              (21) 
In equation (20 ), 
CI  represents the  original input  channel s, where  
MA  is an artificial 
channel generated by  Mth auxiliary learner . Whereas 
(.)kg  is used as a combiner function that 
concatenates the original input channel s with auxiliary channels to generates the channel boosted 
input 
BI  for the discriminator . Equation (21 ) shows the kth resultant feature -map 
k
lF, which is 
generated by convolving  the boosted input  
BIwith kernel  
lkof lth layer.  
Bengio et al.  in 2013 , empirically showed  that data representation plays an important role 
in determining the performance of a classifier , as different representations may present  different 
aspects  of information  (Bengio et al. 2013) . For improving  the representation of the data, Khan et 
al. exploited the power  of TL and deep generative learners  (Qiang Yang et al . 2008; Vincent et 
al. 2008; Hamel and E ck 2010) . Generative learners attempt to characterize the data generating 
distribution during the learning  phase . In CB -CNN, AEs are used as the generative  learner s to 
learn explanatory factors of variation behind  the data. The c oncept  of inductive TL is used in a 
novel way to build a boosted input representation by augmenting learned distribution of the input 
data with the  original channel space ( input  channels). CB -CNN encodes  channel -boosting  phase 
into a generic block , which is inserted at the start of  a deep  network . CB-CNN provides the 
concept that TL can be used at both generation and discrimination stages. The significance of the 
study is that multi -deep learners are used, where generativ e learning models are used as auxiliary 
learners.  These leane rs enhance the representational capacity of deep CNN based discriminator.  
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
42 
arXiv:1901.06032 [cs.CV]  
 
Although the potential  of the channel boosting  was only evaluated by inserting  a boosting block 
at the start, however , Khan et al.  suggested that this idea can be extended by providi ng auxiliary 
channels at any layer  in the deep architecture . CB-CNN has also been  evaluated on the medical 
image dataset  (Aziz et al. 2020) , where it  has shown  improved results , as shown in Table 4 . 
 
 
Fig. 11 Basic architecture of CB -CNN showing the deep auxiliary learners for creating artificial 
channels.  
Table 4 Results of CNN and CB -CNN on mitosis dataset.  
CNN Architecture  F-score  
26 layers deep CNN  0.47 
26 layers deep CB -CNN  0.53 
VGG  0.55 
CB-VGG  0.71 
ResNet  0.44 
CB-ResNet  0.54 
 
4.7 Attention  based  CNN s 
Different levels of abstraction s have an important role in defining the discrimination  power of 
the NN. In addition to learning of multiple hierarchies of abstraction s, focusing on  features 
relevant to the context  also plays a significant role in image localization and recognition. In the 
human  visual system , this phenomenon is referred  to as attention.  Humans view the scene  in a 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
43 
arXiv:1901.06032 [cs.CV]  
 succession of partial glimpses and pay attention to context -relevant  parts. This process not only 
serves to focus sel ected region s but also deduces different interpretatio ns of objects at that 
location and t hus helps in capturin g visual structure in a better way. A more or less s imilar kind 
of interpretability is added into RNN  and LSTM  (Mikolov et al. 2010; Sundermeyer et al. 2012) . 
RNN and LSTM  networks exploit attention module s for the generation  of sequential data , and 
the new samples are weighted based on the ir occurrence in previous iterations . The c oncept  of 
attention was incorporated into CNN , by various researchers to improve representation and 
overcome the computational  limits. This idea of  attention also helps in making CNN intelligent 
enough to recognize  objects even from cluttered  backgrounds and complex scenes . 
4.7.1  Residual  Attention  Neural Network  
Wang et al . proposed a Residual Attention N etwork (RAN) to improve the feature represent ation 
of the network  (Wang et al. 2017a) . The motivation behind the incorporation  of attention in CNN 
was to make a network capable of learning object aware features. RAN is a feed -forward CNN , 
which was built by stacking re sidual blocks with attention module. The a ttention module is 
branched off into trunk and mask branch es that adopt  bottom -up, top-down learning strategy . 
The assembly of two different learning strategies into the attention  module enable s fast feed -
forward p rocess ing and top -down  attention feedback in a single feed -forward process . The 
bottom -up feed -forward structure produces low-resolution  feature -maps with strong semantic 
information. Whereas, top -down architec ture produces dense features to make an infere nce of 
each pixel.   
In the previously  proposed studies , a top-down , bottom -up learning strategy wa s used by 
Restricted Boltzma nn Machines  (Salakhutdinov and Larochelle 2010) . Similarly, Goh et al . 
exploited the top-down  attention mechanism as a regularizing factor in  Deep Boltzma nn 
Machine during the reconstruction phase of the training . The top-down learning strategy globally 
optimizes the network  in such a way that it gradually output  the maps to input during the 
learning  process  (Hinton et al. 2006; Salakhutdinov and Larochelle 2010; Goh et al. 2013) . The 
attention module in RAN  generates object aware soft mask 
(.)smg  at each layer  for input feature -
map 
K
lF  (Xu et al. 2015b) . Soft mask  
(.)smg assign s attention towards object  using equation ( 22) 
by recalibrating trunk branch 
()K
tm lgF  output and thus, behaves like a control gate  for every 
neuron output.   
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
44 
arXiv:1901.06032 [cs.CV]  
                                               
( ) ( ). ( )K K K
am l sm l tm lg g g=F F F                                   (22) 
In one of the previous studies, Transformation network (Jaderberg et al. 2015; Li et al. 
2018)  also exploited  the idea of attention in a simple way by incorporating it with convolution 
block , but the main problem was that attention module s in Transformation network  are fixed and 
cannot adapt to changing circumstances.  RAN  was made efficient towards  recognition of 
cluttered, complex , and noisy images by stacking multiple attention modules. Hierarchical 
organization of RAN endow ed the ability  to adaptivel y assign weight to each feature -map based 
on their relevance in the layers  (Wang et al. 2017a) . Learning of deep hierarchical structure was 
supported through residual units.  Moreover, three different levels of attention: mixed, channel , 
and spatial attenti on were  incorporated , thus leveraging the capability  to capture ob ject-aware 
features  at different levels  (Wang et al. 2017a) .  
4.7.2  Convolutional Block Attention Module  
The significance of attention mechanism and feature -map exploitation is validated through RAN  
and SE-Network  (Wang et al. 2017a; Hu et al. 2018a) . In this regard,  Woo et al.  came up with 
new attention -based CNN , named as Convolutional Block Attention Module (C BAM ) (Woo et 
al. 2018) . CBAM is  simple  in design  and similar to SE-Network . SE-Network only considers the 
contribution  of feature -maps in image classification , but it  ignores the spatial locality  of the 
object  in image s. The s patial locatio n of the object  has a vital role in object detection.  
CBAM infer s attention maps sequentially by first applying  feature -map (channel ) 
attention and then spatial attention , to find the refined feature -maps. In literature, generally, 1x1 
convolution and poo ling operations are used for spatial attention. Woo et al.  showed that the 
pooling of features along the spatial  axis generate s an efficient feature descriptor. CBAM 
concatenates average pooling operation  with max -pooling , which generate s a strong spatial 
attention  map.  Likewise, feature -map statistics  were  modeled  using  a combination  of max -
pooling and global average -pooling operation. Woo et al.  showed that max-pooling could  
provide  the clue about d istinctive object features, where as the use of global ave rage pooling 
returns suboptimal inference of feature -map attention. The e xploitation of both average -pooling 
and max-pooling  improves the representational power of the network. These refined feature -
maps not only focus on the important  part but also increa se the representationa l power of the 
selected feature -maps. Woo et al.  empirically show ed that the formulation  of a 3D attention map 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
45 
arXiv:1901.06032 [cs.CV]  
 via the serial learning process helps in the reduction of the parameter s as well as  computational 
cost. Due to the simplici ty of CBAM , it can be integrated easily with any CNN architecture.  
4.7.3  Concurrent Spatial and C hannel Excitation M echanism  
In 2018, Roy et al.  extend ed the work of Hu et al.  by incorporating  the effect  of spatial 
information in combinat ion with feature -map (channel ) information to make it applicable to 
segmentation tasks  (Roy et al. 2018; Hu et al. 2018a) . They introduce d three different modules: 
(i) squeezing  spatially and exciting feature -map information  (cSE), (ii) squeezing feature -map 
and exciting spatial information  (sSE), and (iii) concurrent squeeze and excitation  of spatial and 
feature -map information  (scSE ). In this work, AE based convolutional NN was used for 
segmentation , whereas proposed modules were  inserted after the encoder and decoder layer s. In 
the cSE module , the same concept as that of SE-block  is exploite d. In this module, the scaling  
factor is derived based on  the combination of  feature -maps used for  object detection. As spatial 
information has an important role in segmentation , therefore in the sSE module , the spatial 
locality has been given more importa nce than feature -map information. For this purpose, 
different combinations of feature -maps are selected  and exploited spatially to use them  for 
segmentation. In the last module , scSE , attention to each feature -map, is assigned by deriving 
scaling factor bo th from spatial and feature -map information and thus to highlight the object -
specific feature -maps [117] selectively  (Roy et al. 2018) .  
5 Applications of CNN s 
CNN s have been successfully applied to  different ML relate d tasks,  namely object detection, 
recognition , classification, regression, segmentation, etc ., (Batmaz et al. 2019; Chouhan a nd 
Khan 2019; Wahab et al. 2019) . However, CNN generally needs a large amount of data for 
learning. All of the areas mentioned earlier in which CNN has shown tremendous success have 
relatively sufficient labeled data, such as traffic sign recognition, seg mentation of medical  
images, and the detection of faces, text, pedestrians, and human s in natural images. Some of the 
interesting  applications of CNN are discussed below.  
5.1 CNN based  computer vision and related  applications   
Computer vision  (CV)  focuses  on developing an artificial system that can process visual data , 
including i mages and videos and can effectively understand , and extract useful information f rom 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
46 
arXiv:1901.06032 [cs.CV]  
 it. CV encompasses  a number of application areas such as face recognition, pose estimation, 
activity recognition, etc.   
Face recognition  is one of the difficult  tasks in the CV. Face recognition systems have to 
cope with variations such as  caused by illumination, change in pose, and different facial 
expressions. Farfade  et al. (2015) proposed deep  CNN for detecting face s from different pose s as 
well as from  occluded faces  (Farfade et al. 2015) . In another work,  Zhang et al. performed face 
detection using a new type of multitasking cascaded CNN  (Zhang et al. 2016) . Zhang’s 
technique showed good resul ts when compared to state-of-the-art techniques (Li et al. 2015; 
Ranjan et al. 2015; Yang et al. 2015) . 
Human pose estimation is one of the  challenging  tasks  related to CV because of the high 
variability in body pose. Li et al. (2014) propose d a hete rogeneous deep CNN based pose 
estimation related technique  (Li et al. 2014) . In Li’s technique, empirical results have shown that 
the hidden neurons can learn the localized part of the body. Sim ilarly, another cascade based 
CNN technique is proposed by Bulat et al. (Bulat and Tzimiropoulos 2016) . In their cascaded 
architecture, first hea t maps are detected, whereas , in the second p hase, regression is performed 
on the detected heat maps.  
Action recognition is one of the important areas of  activity recognition. The difficulties in 
developing an action recognition system are to  solve the translations and distortions of features 
in diff erent patterns, which belong to the same action class. Earlier approaches involved the 
construction of motio n history images, the use of Hidden Markov Models , action sketch 
generation , etc. Recently, Wang et al. (Wang et al. 2017b)  proposed a three dimensional CNN 
architecture in combination  with LSTM for recognizing different actions from video frames. 
Experimental results have shown that Wang’s technique outperforms other  activity recognition 
based techniques (Wang and Schmid 2013; Simonyan a nd Zisserman 2014; Donahue et al. 2015; 
Sun et al. 2015; Tran et al. 2015) . Similarly, another three dimens ional CNN based action 
recognition system is proposed by Ji et al. (Ji et al. 2010) . In Ji’s work, three -dimensional CNN 
is used to extract features from multiple channels of input frames. The final action recognition 
based model is developed on combined extracted feature space . The propose d three dimensional 
CNN model is trained in a supervised way and can perform activity recognition in real-world  
applications.  
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
47 
arXiv:1901.06032 [cs.CV]  
 5.2 CNN  based natural language processing  
Natural Language Processing (NLP) converts  language into a presentation that can easily be 
exploit ed by any computer. Although  RNNs are  very suitable for NLP applications, however, 
CNN s have also been utilized in NLP based applications such as language modeling, and 
analysis, etc. Especially, lang uage modeling  or sentence molding  has taken a t wist after the 
introduction of CNN as a new representation learning algorithm. Sentence modeling is 
performed to know semantics of the sentences and thus offer new and appealing applications 
according to custo mer requirements. Traditional methods of information retrieval  analyze data, 
based on words or features, but ignore the core of the sentence. Kalchbrenner et al. (2014 ) 
proposed a dynamic CNN and dynamic k-max pooling during training. This approach finds t he 
relations between words without taking into account any ext ernal source like parser or 
vocabulary (Kalchbrenner et al. 2014) . In a similar way, Collobert and Weston (2008)  proposed 
CNN based architecture that can perform various MLP related tasks at the s ame time as 
chunking, language modeling, recognizing name -entity, and role modeling related to semantics 
(Collobert and Weston 2008) . In another work, Hu et al. proposed a generic CNN based 
archit ecture that performs matching between two sentences and thus can be applied to different 
languages (Hu et al. 2011) . 
5.3 CNN based  object d etection  and segmentation  
Object detection focuses on identifying different objects in images.  Recently, R-CNN has been 
widely used f or object detection. Ren et al. (2015) proposed an improvement over R -CNN 
named as fast R -CNN for object detection  (Ren et al. 2015) . In their work , a fully connected 
convolution al neural network  is used to extract feature space that can simultaneously detect the 
boundary and score of object s located at different positions. Similarly, Dai et al. (2016) proposed 
region -based  object detection using fully connected CNN  (Dai et al. 2016) . In Dai’s work , results 
are reported on the PASCAL VOC image dataset. Another object detection technique is reported  
by Gidaris et al. (Gidaris and Komodakis 201 5), which is based on multi -region  based deep CNN 
that helps to learn the semantic aware features. In Gidaris’s approach, objects are detected with 
high accuracy on PASCAL VOC 2007 and 2012 dataset.  Recently, AE based CNN  architectures  
have shown success  in segmentation task s. In this regard, various interesting  CNN architectures 
have been reported  for both semantic and instance -based segmentation tasks such as FCN, 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
48 
arXiv:1901.06032 [cs.CV]  
 SegNet, Mask R-CNN , U-Net etc ., (Ronneberger et al. 2015; Badrinaray anan et al. 2017; He et 
al. 2017; Zhan g et al. 2018b) .  
5.4 CNN based  image c lassification  
CNN  has been widely used for image  classification (Levi and Hassner 2009; Lon g et al. 2012; 
Sermanet et al. 2012) . One of the primary applications of CNN is in medical images , especi ally 
for the diagnosi s of cancer using histopathological images  (Cireşan et al. 2013) . Recently, 
Spanhol et al. (2016 ) used CNN for the diagnosis of breast cancer images , and results are 
compared against a network trained on a dataset contain ing handcrafted  descriptors (Spanhol et 
al. 2016a, b) . Another recently proposed CNN based technique for breast cancer diagnosis is 
developed by Wahab et al. (Wahab et al. 2017) . In Wahab’s work, two phases are involved. In 
the first phase, hard non -mitosis examples are identified. In the second phase , data au gmentation 
is performed to cope with the class skewness problem. Similarly, Ciresan et al. (Cireşan et al. 
2012)  used the German benchmark d ataset related to a traffic sign signal . They designed  CNN 
based architecture that performed traffic sign classification related task with a good recognition 
rate. 
5.5 CNN  based speech recognition  
Deep CNN is mostly considered as the best option to deal with image processing applications, 
however ; recent stu dies have shown that it also performs well on speech recognition tasks. 
Hamid et a l. reported a CNN based spe aker-independent speech recognition system (Abdel -
Hamid et al. 2012) . Experimental results showed a ten percent reduction in error rate in 
comparison to the earlier reported methods (Dahl et al. 2010; Mohamed et al. 2012) . In anot her 
work , various CNN architectures, which are either based on the full or limited number of weight 
sharing w ithin the convolution layer, are explored (Abdel -Hamid et al. 2013) . Furthermore, the 
performance of CNN is also evaluated after the initialization of the network using the pre-
training phase (Mohamed et al. 2012) . Experimental results showe d that almost all of the 
explored architectures yield good performance on phone and vocabulary recognition related 
tasks. Now adays , the utilization of  CNNs for speech emotion recognition is also gaining 
attention. Huang et al. used CNN in combination with LSTM for recognizing emotions of 
speech. In Huang’s approach, CNN was trained both on verbal and nonverbal segments  of 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
49 
arXiv:1901.06032 [cs.CV]  
 speech , and CNN learned features were used by LSTM for recognizing speech em otions  (Huang 
et al. 2019) .  
5.6 CNN based  video p rocessing  
In video processing techniques, temporal and spatial information from videos  is exploited. Many 
researchers have used CNN to solve various video processing -related problems  (Tong et al. 
2015; Frizzi et al. 2016; Shi et al. 2017; Ullah et al. 2017; Wang et al. 2017 b). Tong et al. 
proposed CNN based short bou ndary detection system. In Tong’s approach, TAGs are generated 
using CNN  (Tong et al. 2015) . Durin g the experiment, the merging of TAGs against  one-shot is 
performed to annotate vide o against that shot. Similarly,  Wang et al.  used 3 -D CNN along with 
LSTM to recognize action within the video  (Wang et al. 2017b) . In another technique, Frizzi et 
al. used CNN for detecting smoke and fire within the video  (Frizzi et al. 2016) . In Frizzi ’s 
approach, CNN architecture not  only extracts salient features  but also performs the classification 
task. In the field of action recognition, the gathering of spatial and temporal inf ormation is 
considered as a tedi ous task. In order to overcome the deficiencies of traditional feature 
descriptors, Tian et al.  (Shi et al. 2017)  proposed a three stream -based structure, which is capable 
of extract ing spatial -temporal features al ong with short and long term mot ion within  the video. 
Similarly, in another technique , CNN , in combination  with bi -directional LSTM , is used for 
recognizing action from the video  (Ullah et al. 2017) . Their approach comprises of two phases. 
In the first phase, features are extracted from the sixth frame of the videos. In the second phase, 
sequential information between features of the frame is explo ited using the bi-directional LSTM 
framework.  
5.7 CNN for low resolution i mages  
In the field of ML, different researchers have used CNN based image enhancement technique s 
for enhancing the resoluti on of the images (Chevalier et al. 2015; Peng et al. 2016; Kawashima et 
al. 2017) . Peng et al. used deep CNN based approach, which categorizes the object s in imag es 
having low resolution  (Peng et al. 2016) . Similarly, Chevalier et al. introduced LR -CNN for low -
resolution image clas sification (Chevalier et al. 201 5). Another, the deep learning based 
technique is reported by Kawashima et al., in which convolutional layers , along with a layer of 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
50 
arXiv:1901.06032 [cs.CV]  
 LSTM is used to recognize action from thermal images of low resolution  (Kawashima et al. 
2017) . 
5.8 CNN for resource l imited s ystems  
Despite CNN ’s high computational cost, it has been successfully utilized in develo ping different 
ML based embedded systems (Bettoni et al. 2017; Lee et al. 201 7; Xie et al. 2018) . Lee et al. 
developed the number  plate  recognition system, which is capable of qui ckly recognizing the 
number on the license plate  (Lee et al. 2017) . In Lee’s technique, the deep learning based 
embedded recognition sys tem comprises  of simple Al exNet architecture. In order to address 
power efficiency and portability for embedded pla tforms, Bettoni et al. implemented  CNN on the 
FPGA  platfo rm (Bettoni et al. 2017) . In another technique, the FPGA embedded platform is used 
for efficiently perfo rming different CNN based ML tasks (Xie et al. 2018) . Similarly, resource -
limited CNN architectures such as MobileNet, ShuffleNet, ANTNets , etc. are highly applicable 
for mobile devices (Howard et al. 2017; Z hang et al. 2018a; Xiong et al. 2019) . Shakeel  et al. 
developed a real -time based driver drowsiness detection application for smart devices such as 
android phones. They used MobileNet architecture in combination with SSD to exploit the 
benefit of the lightweight architecture of MobileNet that can be easily deploy ed on resource -
constrained hardware  and can learn enriched representation from the incoming  video  (Shakeel et 
al. 2019) .  
5.9 CNN  for 1D -Data 
CNN has not only shown good perfor mance on images but also on 1D-data. The u se of 1D -CNN 
as compared to other ML methods is becoming  popular  because of its good feature extrac tion 
ability . Vinayakumar  et al. used 1D-CNN in combination with RNN, LSTM , and gated recurrent 
units for intrusion detection in network traffic (Vinayakumar et al. 2017) . They evaluated the 
performance of the proposed models on  the KDDCup  99 dataset consisting o f network traffic of 
TCP/IP packets and show ed that CNN significantly surpass es the performance of classical ML 
models. Abdeljaber et al . showed that 1D-CNN could  be used for real -time structural damage 
detection problem  (Abdeljaber et al. 2017) . They develop ed an end -to-end system that can 
automatically extract damage -sensitive features from accelerated  signals for detection purpose s. 
Similarly, Yildirim  et al. showed  the successful use of CNN for the 1D biomedical datas et. 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
51 
arXiv:1901.06032 [cs.CV]  
 Yildirim et al. developed 16 layers deep 1D -CNN based application for mobile devices and a 
cloud -based environment for detecting cardiac irregularity in ECG signals. They achieved 
91.33% accuracy on the MIT-BIH Arrhythmia database (Yıldırım et al. 2018) .  
 
Table 5a Major challenges associated with implementation of Spatial exploitation bas ed CNN architectures.  
Spatial 
Exploitation  As convolutional operation considers the neighborhood ( correlation ) of input pixels, therefore different levels of 
correlation can be expl ored by using different filter size s. 
Architecture  Strength  Gaps  
LeNet  • Exploited spatial correlation to reduce the computation and number of parameters  
• Automatic learning of feature hierarchies  • Poor scaling to diverse classes of 
images  
• Large size filters  
• Low level feature extraction  
AlexNet  • Low, mid and high -level feature extr action using large and small size filters on initial (5x5 
and 11x11) and last layers (3x3)  
• Give an idea of deep and wide CNN architecture  
• Introduced regularization in CNN  
• Started parallel use of GPUs as an accelerator to deal with complex architectures  • Inactive neurons in the first and 
second layers  
• Aliasing a rtifacts in the learned 
feature -maps due to large filter 
size 
ZfNet • Introduced the idea of parameter tuning by visualizing the output of intermediate layers  
• Reduced both the filter size and stride in the first two layers of AlexNet  • Extra information processing is 
required for visualization  
VGG  • Proposed an idea of effective receptive field  
• Gave the idea of simple and homogenous topology  • Use of computati onally 
expensive fully connected layers  
GoogLeNet  • Introduced the idea of using Mutiscale Filters within the layers  
• Gave a new idea of split, transform , and merge  
• Reduce the number of parameters by using bottleneck layer, global average -pooling at last 
layer and Sparse Connections  
• Use of auxili ary classifiers to improve the convergence rate  • Tedious parameter customization 
due to heterogeneous topology  
• May lose the useful information 
due to representational bottleneck  
 
 
Table 5b Major challenges associated with implementation of Depth based CNN a rchitectures.  
Depth  With the increase in depth, the network can better approximate the target function with a number of nonlinear mappings 
and improved feature representations.  Main challenge fa ced by deep architectures is the problem  of vanishing gradient  and 
negative learning.  
Architecture  Strength  Gaps  
Inception -V3 • Exploited asymmetric filters and bottleneck layer to lessen the computational cost of deep 
architectures  • Complex architecture design  
• Lack of homogeneity  
Highway  
Networks  • Introduced trainin g mechanism for deep networks  
• Used auxiliary connections in addition to direct connections  • Parametric gating mechanism, 
difficult to implement  
Inception -
ResNet  • Combined the power of residual learning and inception block  - 
Inception -V4 • Deep hierarchies o f features, multilevel feature representation  • Slow in learning  
ResNet   
• Decreased the error rate for deeper networks  
• Introduced the idea of residual learning  
• Alleviates the effect of vanishing gradient problem  • A little complex architecture  
• Degrad es informa tion of 
feature -map in feed forwarding  
• Over adaption of hyper -
parameters for specific task, due 
to the stacking of same modules  
 
 
 
 
 
 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
52 
arXiv:1901.06032 [cs.CV]  
  
Table 5c Major challenges associated with implementation of Multi -Path based CNN architectures.  
Multi -Path Shortcut paths provides the option to skip some layers. Different types of the shortcut connections used in literature are 
zero padded, projection, dropout, 1x1 con nections, etc.  
Architecture  Strength  Gaps  
Highway 
Networks  
 • Mitigates the limitations of deep networks by  introducing cross layer connectivity.  • Gates are data dependent and 
thus may become parameter 
expensive  
ResNet  
 • Use of identity based  skip connections to enable cross layer connectivity  
• Information flow gates are data independent and parameter free  
• Can ea sily pass the signal in both directions, forward and backward  • Many layers may contribute 
very little or no information  
• Relearning of r edundant feature -
maps may happen  
DenseNet  • Introduced depth or cross -layer dimension  
• Ensures maximum data flow between the  layers in the network  
• Avoid relearning of redundant feature -maps  
• Low and high level both features are accessible to decision layers  • Large increase in parameters 
due t o increase in number of 
feature -maps at each layer  
 
Table 5d Major challenges associated  with implementation of Width based CNN architectures.  
Width  Earlier, it was assumed that to improve accuracy, the number of layers h ave to be increased. However, by increasing the 
number of layers, the  vanishing  gradient p roblem arises and training might get slow. So, the concept of widening a layer 
was also investigated.  
Architecture  Strength  Gaps  
Wide ResNet  
 • Showe s the effectiveness of parallel use of transformations by increasing the width of 
ResNet and decreasing its depth  
• Enables feature reuse  
• Have  shown that dropouts between the convolutional  layer are more effective  • Over fitting may occur  
• More parameters than t hin deep 
networks  
Pyramidal Net  
 • Introduces the idea of increasing the width gradually per unit  
• Avoids rapid information loss  
• Covers all p ossible locations instead of maintaining the same dimension till last unit  • High spatial and time 
complexity  
• May become quite complex, if 
layers are substantially 
increased  
Xception  
 • Introduce the concept that learning across 2D followed by 1 D is easier t han to learn filters 
in 3 D space  
• Depth -wise separable convolution is introduced  
• Use of cardinality to learn good abstractions  • High computational cost  
Inception  • Varying size filters inside inception module increases the output of the intermediate layers  
• Varying size filters are helpful to capture the diversity in high -detail images  • Increase in space and time 
complexity  
 
ResNeX t • Introduced cardinality to avail diverse transformations at each layer  
• Easy parameter customization due to homogenous topology  
• Uses grouped convolution  • High computational cost  
 
Table 5e Major challenges associated with implementat ion of Feature -Map exploitation based CNN architectures.  
Feature -
Map 
Selection  As the deep learning topology is extended, more and more features maps are g enerated at  each step. Many of the Feature -
maps might be important for classification task, others mi ght redundant or  less important. Hence, feature -map selection is 
another important dimension in deep learning architectures . 
Architecture  Strength  Gaps  
Squeeze and 
Excitation 
Network  
 • It is a block -based concept  
• Introduced a generic block that can be added easily in any CNN model due to its 
simplicity  
• Squeezes less important features and vice versa  
 • In ResNet, it only considers the 
residual information for  
determining the weight of each 
channel  
Competitive 
Squeeze and 
Excitation 
Networks  
 • Uses feature -map wise statistics from both residual and identity mapping based features  
• Makes a competition betwee n residual and identity feature -maps  • Doesn’t support the  concept of 
attention  
 
 
 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
53 
arXiv:1901.06032 [cs.CV]  
  
Table 5f Major challenges associated with implementation of Channel Boosting based CNN architectures.  
Channel  
Boosting  The learning of CNN also relies on the input representation. The lack of diversity and absence of class discer nable 
information in the input may affect CNN performance. For this purpose, the concept of channel boosting (input channel 
dimension) using auxil iary learners is introduced in CNN to boost the representation of the network (Khan et al. 2018a) . 
Architecture  Strength  Gaps  
Channel 
Boosted CNN 
using  Transfer 
Learning  
 • It boosts the number of input channels for improving the representational  capacity of 
the network  
• Inductive Transfer Learning is used in a novel way to build a boosted input 
representation for CNN  • Increases in computational load 
may hap pen due to the 
generation of auxiliary channels  
 
Table 5g Major challenges associated with implementation of Attention based CNN architectures.  
Attention  Attention Networks advantages to choose which patch is the area of the focus or most important in an image  
Architecture  Strength  Gaps  
Residual 
Attention 
Neural 
Network  
 • Generates attention aware featur e-maps  
• Easy to scale up due to residual learning  
• Provides different representations of the focused patches  
• Adds soft weights on features using bottom up top-down feedforward attention  • Complex model  
 
Convolutional 
Block 
Attention 
Module  • CBAM is a generic block designed for feed forward convolutional neural networks.  
• Generate both feature -map and spatial attention in a sequential manner  
• Channel attention ma ps help what to focus.  
• Spatial attention helps where to focus.  
• Increases efficient flow of information.  
• Uses global avera ge pooling and max pool simultaneously.  • Increase in computational load 
may happen  
 
6 CNN c hallenges  
Deep CNNs have achieved good performance on data that either is of the time series nature or 
follows a grid-like topology. However, there are also some other challenges, where dee p CNN 
architectures have been put to tasks. Major challenges associated with different CNN 
architec tures ar e mentioned in Table 5 a-g. The different researchers related to the performance of 
CNN on different ML tasks have  interesting discussions . Some of th e challenges faced during 
the training of deep CNN models are given below:  
• Deep CNNs are generally like a black box and thus may lack in interpretation and 
explanation. Therefore, sometimes it is difficult to verify them.  
• Szegedy et al. (2013) showed that  training of CNN on noisy image data could  cause an 
increase of misclassification error (Szegedy et al. 2014) . The addition of the small 
quantity of random noise in the input image is capable of fooling the network in such a 
way that the mod el will classify the original and its slightly perturbed version differently.   
• Each layer of CNN autom atically tri es to extract better and proble m-specific features 
related to the task. However, for some tasks,  it is imperative  to know the nature of 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
54 
arXiv:1901.06032 [cs.CV]  
 featu res extracted by the deep CNNs before classification. The idea of feature 
visualization in CNNs  can help in this direction. Similarly, Hinton reported that lower 
layers should handover their knowledge only to the relevant neuron s of the next layer. In 
this regard, Hinton proposed an interesting Capsule Network approach (de Vries et al. 
2016; Hinton et al. 2018) . 
• Deep CNNs  are based on supervised learnin g mechanism s, and therefore,  the availability 
of large and annotated data is required for its proper learning. In contrast, humans can 
learn and generalize from a few examples.  
• Hyper -parameter selection highly influences the performance of CNN. A little ch ange in 
the hyper -parameter values can affect the overall performance of a CNN. That is why 
careful selection of hyper -parameters is a major design issue that needs to be addressed 
through some suitable optimization strategy.  
• The e fficient training of CNN demands powerful hardware r esources such as GPUs. 
However, it is still needed to employ CNNs in embedded and smart devices efficiently . A 
few applications of deep learning in embedded systems are wound intensity correction, 
law enf orcement in smart cities, etc., (Hinton et a l. 2011, 2012a; Lu et al. 2017a) . 
• In vision -related  tasks, one shortcoming of CNN is that it is generally  unable to show 
good performance  when used to estimate the pose, orientation, and location of an o bject. 
In 2012, AlexNet solved this problem to some extent  by introducing the concept of data 
augmentation. Data augmentation can help CNN in learning diverse internal 
representations, which ultimately may lead to improved performance.  
7 Future d irections  
The exploitation of different innovative ideas  in CN N architectural design has changed the 
direction of research , especially  in image processing and CV . Good  performance of CNN on  a 
grid-like topological data presents  it as a powerful representation al model for image s. 
Architectural  design of CNN is a promi sing research field and in future,  it is likely to  be one of 
the most widely used AI techniques . 
• Ensemble learning  is one of the prospective areas of research in CNNs  (Marmanis et al. 
2016; Ahmed et al. 2019) . The combination of multiple and diverse architectures can aid 
the model in improvin g generalization and robustness on diverse categories of images by 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
55 
arXiv:1901.06032 [cs.CV]  
 extracting different levels of semantic represen tation s. Similarly, concepts such as batch 
normalization, dropout, and new activation functions are also worth mentioning.  
• The potential of  a CNN as a generative learner is exploi ted in image segmentation tasks, 
where it has shown good results  (Kahng et al. 2019) . The exploitation of generative 
learnin g capabilities of CNN s at feature extraction stages can boost the representation al 
power of the model. Similar ly, new paradigms are needed that can enhance the learning 
capacity of CNN by inco rporating informative feature -maps that can be  learned  using  
auxiliary learners at the intermediate stages of CNN  (Khan et al. 2018a) .  
• In the human visual system, attention is  one of the important mechanisms in cap turing 
information from images.  The a ttention mechanism operates in such a way that it not 
only extract s the essential information from image but al so store s its contextual relation  
with other components of image  (Bhunia et al. 2019) . In the future, resear ch may be 
carried out in the direction that preserves the spatial relevance of object s along with their 
discriminating features at later stages of learning.  
• The learning capacity of CNN is generally enhanced by increasing  the size of the 
network , and it can be done in a reasonable time with the help of the current advanced  
hardware technology  such as Nvidia DGX -2 supercomputer . However, the training of 
deep and high capacity architectures is still a significant overhead on memory usage and 
computation al resources  (Lacey et al. 2016; Sze et al. 2017; Justus et al. 2019) . 
Consequently, we still require  many  improv ement s in hardware technology  that can 
accelerate research in CNNs . The main concern with CNNs  is the run -time applicability. 
Moreover,  the use of CNN is hindered in small hardware, especially in mobile devices , 
because of its high computational cost. In this regard, different hardware accelerators are 
needed for reducing both execution time and po wer consumption  (Geng et al. 2019) . 
Some of the very interesting accelerators are already proposed. For exa mple,  Application 
Specific Integrated Circuits, FPGA, and Eyeriss are well known  (Moons and Verhelst 
2017) . Moreover, different operations have been performed to minimize the  hardware 
resources in terms of chip area and energy requirement , by reduci ng floating -point 
precision of op erands and ternary quantization  or minimizing  the number of matrix 
operations. N ow it is also time to redirect research towards hardware -oriented 
approximation models  (Geng et al. 2019) .  
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
56 
arXiv:1901.06032 [cs.CV]  
 • Deep CNN has a large number of hyper -paramete rs such as activation function, kernel 
size, number of neurons per layers, and arrangement of layers , etc. The selection of 
hyper-parameters and the evaluation  time of a deep network , make  parameter tuning 
quite a difficult  job. Hyper -parameter tuning  is a tedious and intuition driven task, which 
cannot be defined via explicit formulation. In this regard, Genetic algorithms  can also be 
used to automatically optimize  the hyper -parameter s by performing search es both in a 
random fashion as well as by  directing  search by utilizing  previous results  (Young et al. 
2015; Sug anuma et al. 2017; Khan et al. 2019) .  
• In order  to overcome hardware limitations, the concept  of pipeline parallelism can be 
exploited to scale up deep C NN training. Google group has proposed a distributed ML 
library  GPipe  (Huang et al. 2018)  that offers  a  model parallelism option for training . In 
the future , the concept of pipelining can be used  to accelerate the training of large  models 
and to scale the performance without tuning hyper -parameters.  
• In the future , it is expected that the potential of cloud -based platforms will be exploited 
for the development of computationally intensive CNN  appli cations  (Akar et al. 2019 ; 
Stefanini et al. 2019) . Deep and wide CNNs present  a critical challenge in implementing 
and executing them  on resource -limited  devices . Cloud computing not only allow s 
dealing  with a massive amount of data but also leverage s the benefit of  high 
computat ional efficiency at a negligible cost . World -leading companies such as Amazon, 
Microsoft, Google, and IBM offer the public cloud computing facilities  at high 
scalability, speed , and flexibility  to train resource -hungry CNN architectures . Moreover, 
the cloud environment  make s it easy to configure libraries both for re searchers and new  
practitioners.  
• CNN s are mostly used for image processing applications , and therefore, the 
implementation of the state-of-the-art CNN architectures on sequential  data require s the 
conversion of 1D -data into 2D -data. Due to the good feature extraction ability and 
efficient computations with the limited number of parameters, the trend  of using 1D -
CNNs is being promoted for sequential data  (Vinayakumar et al. 2017; Madrazo et al. 
2019) . 
• Recently high energy physicists at CERN have also been utilizing the learning capability 
of CNN for the analysis of particle colli sions. It is expected that the use of ML and 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
57 
arXiv:1901.06032 [cs.CV]  
 specifically  that of  deep CNN in high energy physics will grow  (Aurisano et al. 2016; 
Madrazo et al. 201 9).  
8 Conclusion  
CNN has made remarkable progress, espec ially in image processing and vision -related tasks, and 
has thus revived the interest of researchers  in ANNs. In this context, several research works have 
been carried out to improve CNN’s performance on such tasks. T he advancements in CNNs can 
be categori zed in different ways, including activation, loss function, optimization, regularization, 
learning algorithms, and innovations in architecture. This paper reviews advancement in the 
CNN architectures, especially based  on the design patterns of the processi ng units and thus has 
proposed the taxonomy for recent CNN architectures. In addition to the categorization of CNNs 
into different classes, this paper also covers the history of CNNs, its applications, challenges, and  
future directions.  
The learning capac ity of CNN is significantly improved over the years by exploiting 
depth and other structural modifications. It is observed in recent literature that the main boost in 
CNN performance has been achieved by replacing the  conventional layer structure with bloc ks. 
Nowadays, one of the paradigms of research in CNN architectures is the development of new 
and effective block architectures. The role of a block in a network can be that of an auxiliary 
learner. These auxiliary le arners either exploit spatial or featur e-map information or even boost 
input channels to improve performance. These blocks play a significant role in boosting CNN 
performance by making problem -aware learning.  
Moreover, the block -based architecture of CNN e ncourages learning in a modular fashion  
and thereby, making architecture simpler and more understandable . The concept of the block 
being a structural unit is going to persist and further enhance CNN performance. Additionally, 
the idea of attention and expl oitation of channel information, in add ition to spatial information, is 
expected to gain more importance.  
Acknowledgments  
The authors would like to  thank  Pattern Recognition lab  at DCIS , and PIEAS  for providing them  
computational facilities.  The authors express their gratitude to M . Waleed Kha n of PIEAS for the 
detailed discussion related to the Mathematical description of the different CNN architectures.  
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
58 
arXiv:1901.06032 [cs.CV]  
  
References  
Abbas Q, Ibrahim MEA, Jaffar M A (2019) A comprehensive review of recent advances on deep 
vision systems. Artif Intell Rev 52:39 –76. doi: 10.1007/s10462 -018-9633 -3 
Abdel -Hamid O, Deng L, Yu D (2013) Exploring convolutional neural network structures and 
optimization techniques for speech  recognition. In: Interspeech. pp 1173 –1175  
Abdel -Hamid O, Mohamed AR, Jiang H, Penn G (2012) Applying convolutional neural 
networks concepts to hybrid NN -HMM model for speech recognition. ICASSP, IEEE Int 
Conf Acoust Speech Signal Process - Proc 4277 –4280 . doi: 10.1007/978 -3-319-96145 -3_2 
Abdeljaber O, Av ci O, Kiranyaz S, et al (2017) Real -time vibration -based structural damage 
detection using one -dimensional convolutional neural networks. J Sound Vib. doi: 
10.1016/j.jsv.2016.10.043  
Abdulkader A (2006) Two -tier approach for Arabic offline handwriting recog nition. In: Tenth 
International Workshop on Frontiers in Handwriting Recognition  
Ahmed U, Khan A, Khan SH, et al (2019) Transfer Learning and Meta Classification Based 
Deep Churn Prediction System for Tele com Industry. 1 –10 
Akar E, Marques O, Andrews WA, F urht B (2019) Cloud -Based Skin Lesion Diagnosis System 
Using Convolutional Neural Networks. In: Intelligent Computing -Proceedings of the 
Computing Conference. pp 982 –1000  
Amer M, Maul T (2019) A review of modularization techniques in artificial neural netw orks. 
Artif Intell Rev 52:527 –561. doi: 10.1007/s10462 -019-09706 -7 
Aurisano A, Radovic A, Rocco D, et al (2016) A convolutional neural network neutrino event 
classifier. J Instrum. doi: 10.1088/1748 -0221/1 1/09/P09001  
Aziz A, Sohail A, Fahad L, et al (2020)  Channel Boosted Convolutional Neural Network for 
Classification of Mitotic Nuclei using Histopathological Images. In: 2020 17th International 
Bhurban Conference on Applied Sciences and Technology (IBCAST) . pp 277 –284 
Badrinarayanan V, Kendall A, Cipolla R  (2017) SegNet: A Deep Convolutional Encoder -
Decoder Architecture for Image Segmentation. IEEE Trans Pattern Anal Mach Intell. doi: 
10.1109/TPAMI.2016.2644615  
Batmaz Z, Yurekli A, Bilge A, Kaleli C (2019) A review on deep learning for recommender 
systems: challenges and remedies. Artif Intell Rev 52:1 –37. doi: 10.1007/s10462 -018-9654 -
y 
Bay H, Ess A, Tuytelaars T, Van Gool L (2008) Speeded -Up Robust Features (SURF). Comput 
Vis Image Underst 110:346 –359. doi:  10.1016/j.cviu.2007.09.014  
Bengio Y (2009) Learnin g Deep Architectures for AI. Found Trends® Mach Learn 2:1 –127. doi: 
10.1561/2200000006  
Bengio Y (2013) Deep learning of representations: Looking forward. In: International 
Conference on Statistical Languag e and Speech Processing. Springer, pp 1 –37 
Bengio Y , Courville A, Vincent P (2013) Representation learning: A review and new 
perspectives. IEEE Trans Pattern Anal Mach Intell 35:1798 –1828. doi: 
10.1109/TPAMI.2013.50  
Bengio Y, Lamblin P, Popovici D, Laroche lle H (2007) Greedy layer -wise training of deep 
networks. In: Advances in neural information processing systems. The MIT Press, pp 153 –
160 
Berg A, Deng J, Fei -Fei L (2010) Large scale visual recognition challenge 2010  
Bettoni M, Urgese G, Kobayashi Y, et al (2017) A Convolutional Neural Network Fully 
Imple mented on FPGA for Embedded Platforms. 49 –52. doi: 10.1109/NGCAS.2017.16  
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
59 
arXiv:1901.06032 [cs.CV]  
 Bhunia AK, Konwer A, Bhunia AK, et al (2019) Script identification in natural scene image and 
video frames using an  attention based Convolutional -LSTM network. Pattern Recognit 
85:172 –184 
Boureau Y (2009) Icml2010B.Pdf. doi: citeulike -article -id:8496352  
Bouvrie J (2006) 1 Introduction Notes on Convolutional Neural Networks. doi: 
http://dx.doi.org/10.1016/j.protcy.2014.09.007  
Bulat A, Tzimiropoulos G (2016) Human Pose Estimation via Con volutional Part Heatmap 
Regression BT  - Computer Vision – ECCV 2016. In: Leibe B, Matas J, Sebe N, Welling M 
(eds). Springer International Publishi ng, Cham, pp 717 –732 
Cai Z, Vasconcelos N (2019) Cascade R -CNN: High Quality Object Detection and Instance 
Segmentation. IEEE Trans Pattern Anal Mach Intell. doi: 10.1109/tpami.2019.2956516  
Chapelle O (1998) Support vector machines for image classification . Stage deuxième année 
magistère d’informatique l’École Norm Supérieur Lyon 10:1055 –1064. doi: 
10.1109/72.78 8646  
Chellapilla K, Puri S, Simard P (2006) High performance convolutional neural networks for 
document processing. In: Tenth International Workshop  on Frontiers in Handwriting 
Recognition  
Chen W, Wilson JT, Tyree S, et al (2015) Compressing neural network s with the hashing trick. 
In: 32nd International Conference on Machine Learning, ICML 2015  
Chen Y -N, Han C -C, Wang C -T, et al (2006) The application  of a convolution neural network on 
face and license plate detection. In: Pattern Recognition, 2006. ICPR 20 06. 18th 
International Conference on. pp 552 –555 
Chevalier M, Thome N, Cord M, et al (2015) LR -CNN for fine -grained classification with 
varying reso lution. In: 2015 IEEE International Conference on Image Processing (ICIP). 
IEEE, pp 3101 –3105  
Chollet F (201 7) Xception: Deep learning with depthwise separable convolutions. arXiv Prepr 
1610 –2357  
Chouhan N, Khan A (2019) Network anomaly detection using cha nnel boosted and residual 
learning based deep convolutional neural network. Appl Soft Comput 105612  
Ciresan D, Giusti A, Gambardella LM, Schmidhuber J (2012) Deep neural networks segment 
neuronal membranes in electron microscopy images. In: Advances in neu ral information 
processing systems. pp 2843 –2851  
Cireşan D, Meier U, Masci J, Schmidhuber J (2012) Multi -column deep neural network for 
traffic sign classification. Neural Networks 32:333 –338. doi: 10.1016/j.neunet.2012.02.023  
Ciresan DC, Ciresan DC, Meier  U, Schmidhuber J (2018) Multi -column deep neural networks 
for image classification. IEEE Comput Soc Conf Co mput Vis Pattern Recognit  
Cireşan DC, Giusti A, Gambardella LM, Schmidhuber J (2013) Mitosis Detection in Breast 
Cancer Histology Images with Deep N eural Networks BT  - Medical Image Computing and 
Computer -Assisted Intervention – MICCAI 2013. In: Proceedin gs MICCAI. pp 411 –418 
Ciresan DC, Meier U, Gambardella LM, Schmidhuber J (2010) Deep , Big , Simple Neural Nets 
for Handwritten. Neural Comput 22:32 07–3220  
Cireşan DC, Meier U, Masci J, et al (2011) High -Performance Neural Networks for Visual 
Object Classi fication. arXiv Prepr arXiv11020183  
Collobert R, Weston J (2008) A unified architecture for natural language processing: Deep 
neural networks with m ultitask learning. In: Proceedings of the 25th international 
conference on Machine learning. ACM, pp 160 –167 
Csáji B (2001) Approximation with artificial neural networks. MSc thesis 45. doi: 
10.1.1.101.2647  
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
60 
arXiv:1901.06032 [cs.CV]  
 Dahl G, Mohamed A, Hinton GE (2010) Phone recogni tion with the mean -covariance restricted 
Boltzmann machine. In: Advances in neural information processing sy stems. pp 469 –477 
Dahl GE, Sainath TN, Hinton GE (2013) Improving deep neural networks for LVCSR using 
rectified linear units and dropout. In: Acous tics, Speech and Signal Processing (ICASSP), 
2013 IEEE International Conference on. IEEE, pp 8609 –8613  
Dai J , Li Y, He K, Sun J (2016) R -FCN: Object Detection via Region -based Fully Convolutional 
Networks. doi: 10.1016/j.jpowsour.2007.02.075  
Dalal N, Trigg s W (2004) Histograms of Oriented Gradients for Human Detection. 2005 IEEE 
Comput Soc Conf Comput Vis Patter n Recognit CVPR05 1:886 –893. doi: 
10.1109/CVPR.2005.177  
Dauphin YN, De Vries H, Bengio Y (2015) Equilibrated adaptive learning rates for non -convex 
optimization. Adv Neural Inf Process Syst 2015 -Janua:1504 –1512  
Dauphin YN, Fan A, Auli M, Grangier D (2017) Language modeling with gated convolutional 
networks. In: Proceedings of the 34th International Conference on Machine Learning -
Volume 70. pp 933 –941 
de Vries H, Memisevic R, Courville A (2016) Deep learning vector quantization. In: European 
Symposium on Art ificial Neural Networks, Computational Intelligence and Machine 
Learning  
Decoste D, Schölkopf B (2002) Training invariant support vector machines. Mach Learn 
46:161 –190 
Delalleau O, Bengio Y (2011) Shallow vs. deep sum -product networks. In: Advances in Neu ral 
Information Processing Systems. pp 666 –674 
Deng L (2012) The MNIST database of handwritten digit images for machine learning research  
[best of the web]. IEEE Signal Process Mag 29:141 –142 
Deng L, Yu D, Delft B — (2013) Deep Learning: Methods and Applica tions Foundations and 
Trends R in Signal Processing. Signal Processing 7:3 –4. doi: 10.1561/2000000039  
Do MN, Vetterli M (2005) The contou rlet transform: an efficient directional multiresolution 
image representation. IEEE Trans image Process 14:2091 –2106  
Dollár P, Tu Z, Perona P, Belongie S (2009) Integral channel features  
Donahue J, Anne Hendricks L, Guadarrama S, et al (2015) Long -term rec urrent convolutional 
networks for visual recognition and description. In: Proceedings of the IEEE conference on 
compute r vision and pattern recognition. pp 2625 –2634  
Dong C, Loy CC, He K, Tang X (2016) Image super -resolution using deep convolutional 
networ ks. IEEE Trans Pattern Anal Mach Intell 38:295 –307 
Erhan D, Bengio Y, Courville A, Vincent P (2009) Visualizing higher -layer features of a deep 
network. Univ Montr 1341:1  
Farfade SS, Saberian MJ, Li L -J (2015) Multi -view Face Detection Using Deep Convoluti onal 
Neural Networks. In: Proceedings of the 5th ACM on International Conference on 
Multimedia Retrieval - ICMR ’15. AC M Press, New York, New York, USA, pp 643 –650 
Fasel B (2002) Facial expression analysis using shape and motion information extracted by 
convolutional neural networks. In: Neural Networks for Signal Processing, 2002. 
Proceedings of the 2002 12th IEEE Worksho p on. pp 607 –616 
Frizzi S, Kaabi R, Bouchouicha M, et al (2016) Convolutional neural network for video fire and 
smoke detection. In: IECO N 2016 -42nd Annual Conference of the IEEE Industrial 
Electronics Society. IEEE, pp 877 –882 
Frome A, Cheung G, Abdulkade r A, et al (2009) Large -scale privacy protection in Google Street 
View. In: Proceedings of the IEEE International Conference on Computer Vision  
Frosst N, Hinton G rey (2018) Distilling a neural network into a soft decision tree. In: CEUR 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
61 
arXiv:1901.06032 [cs.CV]  
 Workshop Proceedin gs 
Fukushima K (1988) Neocognitron: A hierarchical neural network capable of visual pattern 
recognition. Neural networks 1:119 –130 
Fukush ima K, Miyake S (1982) Neocognitron: A self -organizing neural network model for a 
mechanism of visual pattern recogniti on. In: Competition and cooperation in neural nets. 
Springer, pp 267 –285 
Garcia C, Delakis M (2004) Convolutional face finder: A neural a rchitecture for fast and robust 
face detection. IEEE Trans Pattern Anal Mach Intell. doi: 10.1109/TPAMI.2004.97  
Gardner  MW, Dorling SR (1998) Artificial neural networks (the multilayer perceptron) —a 
review of applications in the atmospheric sciences. Atmos Environ 32:2627 –2636  
Geng X, Lin J, Zhao B, et al (2019) Hardware -Aware Softmax Approximation for Deep Neural 
Networks . In: Lecture Notes in Computer Science (including subseries Lecture Notes in 
Artificial Intelligence and Lecture Notes in  Bioinformatics). pp 107 –122 
Gidaris S, Komodakis N (2015) Object detection via a multi -region and semantic segmentation -
aware U model . Proc IEEE Int Conf Comput Vis 2015 Inter:1134 –1142. doi: 
10.1109/ICCV.2015.135  
Girshick R (2015) Fast R -CNN. In: Proceed ings of the IEEE International Conference on 
Computer Vision. pp 1440 –1448  
Giusti A, Ciresan DC, Masci J, et al (2013) Fast image scan ning with deep max -pooling 
convolutional neural networks. In: 2013 IEEE International Conference on Image 
Processing. IEEE , pp 4034 –4038  
Glorot X, Bengio Y (2010) Understanding the difficulty of training deep feedforward neural 
networks. In: Proceedings of  the thirteenth international conference on artificial intelligence 
and statistics. pp 249 –256 
Goh H, Thome N, Cord M, Lim  J-H (2013) Top -down regularization of deep belief networks. In: 
Advances in Neural Information Processing Systems (NIPS). pp 1878 –1886 
Grill -Spector K, Weiner KS, Gomez J, et al (2018) The functional neuroanatomy of face 
perception: From brain measurement s to deep neural networks. Interface Focus 8:20180013. 
doi: 10.1098/rsfs.2018.0013  
Grün F, Rupprecht C, Navab N, Tombari F (2016) A Ta xonomy and Library for Visualizing 
Learned Features in Convolutional Neural Networks. 48:. doi: 
10.1080/10962247.2014.9482 29 
Gu J, Wang Z, Kuen J, et al (2018) Recent advances in convolutional neural networks. Pattern 
Recognit 77:354 –377. doi: 10.1016/j.pa tcog.2017.10.013  
Guo Y, Liu Y, Oerlemans A, et al (2016) Deep learning for visual understanding: A review. 
Neurocomputing 187:27 –48. doi: 10.1016/j.neucom.2015.09.116  
Hamel P, Eck D (2010) Learning Features from Music Audio with Deep Belief Networks. In: 
ISMIR. Utrecht, The Netherlands, pp 339 –344 
Han D, Kim J, Kim J (2017) Deep Pyramidal Residual Networks. In:  2017 IEEE Conference on 
Computer Vision and Pattern Recognition (CVPR). IEEE, pp 6307 –6315  
Han S, Mao H, Dally WJ (2016) Deep compression: Compressi ng deep neural networks with 
pruning, trained quantization and Huffman coding. In: 4th International Confer ence on 
Learning Representations, ICLR 2016 - Conference Track Proceedings  
Han W, Feng R, Wang L, Gao L (2018) Adaptive Spatial -Scale -Aware Deep Conv olutional 
Neural Network for High -Resolution Remote Sensing Imagery Scene Classification. 
IGARSS 2018 - 2018 IEEE Int Geosci Remote Sens Symp 4736 –4739. doi: 
10.1109/IGARSS.2018.8518290  
Hanin B, Sellke M (2017) Approximating Continuous Functions by ReLU Ne ts of Minimal 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
62 
arXiv:1901.06032 [cs.CV]  
 Width. arXiv Prepr arXiv171011278  
He K, Gkioxari G, Dollar P, Girshick R (2017) Mask R -CNN. I n: Proceedings of the IEEE 
International Conference on Computer Vision  
He K, Zhang X, Ren S, Sun J (2015a) Deep Residual Learning for Image Recogniti on. Multimed 
Tools Appl 77:10437 –10453. doi: 10.1007/s11042 -017-4440 -4 
He K, Zhang X, Ren S, Sun J (2015b) Spatial pyramid pooling in deep convolutional networks 
for visual recognition. IEEE Trans Pattern Anal Mach Intell 37:1904 –1916  
Heikkilä M, Pietikäin en M, Schmid C (2009) Description of interest regions with local binary 
patterns. Pattern Recognit 42:425 –436. doi: 10.1016/j.patcog.2008.08.014  
Hinton G, Deng L, Yu D, et al (2012a) Deep neural networks for acoustic modeling in speech 
recognition: The sha red views of four research groups. IEEE Signal Process Mag 29:82 –97 
Hinton G, Sabour S, Frosst N (2018) Mat rix capsules with EM routing. In: 6th International 
Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings  
Hinton GE, Krizh evsky A, Wang SD (2011) Transforming auto -encoders. In: International 
Conference on Artificial Neural Netwo rks. Springer, pp 44 –51 
Hinton GE, Osindero S, Teh Y -W (2006) A fast learning algorithm for deep belief nets. Neural 
Comput 18:1527 –1554  
Hinton GE, S rivastava N, Krizhevsky A, et al (2012b) Improving neural networks by preventing 
co-adaptation of feature d etectors. arXiv Prepr ArXiv 12070580 1 –18 
Hochreiter S (1998) The vanishing gradient problem during learning recurrent neural nets and 
problem soluti ons. Int J Uncertainty, Fuzziness Knowledge -Based Syst 6:107 –116 
Howard AG, Zhu M, Chen B, et al (2017) Mob ileNets: Efficient Convolutional Neural Networks 
for Mobile Vision Applications. arXiv Prepr arXiv170404861  
Hu B, Lu Z, Li H, Chen Q (2011) Topic mod eling for named entity queries. In: Proceedings of 
the 20th ACM international conference on Information and  knowledge management - 
CIKM ’11. ACM Press, New York, New York, USA, p 2009  
Hu J, Shen L, Sun G (2018a) Squeeze -and-Excitation Networks. In: 2018 IE EE/CVF Conference 
on Computer Vision and Pattern Recognition. IEEE, pp 7132 –7141  
Hu Y, Wen G, Luo M, et al (2018b) Competitive Inner -Imaging Squeeze and Excitation for 
Residual Network. doi: arXiv:1807.08920v3  
Huang G, Liu Z, Van Der Maaten L, Weinberger K Q (2017) Densely connected convolutional 
networks. Proc - 30th IEEE Conf Comput Vis Pattern Recognition, CV PR 2017 2017 -
Janua:2261 –2269. doi: 10.1109/CVPR.2017.243  
Huang G, Sun Y, Liu Z, et al (2016a) Deep networks with stochastic depth. In: European 
Confe rence on Computer Vision. Springer, pp 646 –661 
Huang G, Sun Y, Liu Z, et al (2016b) Deep Networks with Stoc hastic Depth BT  - Computer 
Vision – ECCV 2016. In: European Conference on Computer Vision. Springer, pp 646 –661 
Huang KY, Wu CH, Hong QB, et al (201 9) Speech Emotion Recognition Using Deep Neural 
Network Considering Verbal and Nonverbal Speech Sounds. In:  ICASSP, IEEE 
International Conference on Acoustics, Speech and Signal Processing - Proceedings  
Huang Y, Cheng Y, Bapna A, et al (2018) GPipe: Effici ent Training of Giant Neural Networks 
using Pipeline Parallelism. arXiv Prepr arXiv181106965 2014:  
Hubel DH, Wiesel TN (1962) Receptive fields, binocular interaction and functional architecture 
in the cat’s visual cortex. J Physiol 160:106 –154. doi: 10.111 3/jphysiol.1962.sp006837  
Hubel DH, Wiesel TN (1959) Receptive fields of single neurones in the cat’ s striate cortex. J 
Physiol. doi: 10.1113/jphysiol.1959.sp006308  
Hubel DH, Wiesel TN (1968) Receptive fields and functional architecture of monkey striate 
cortex. J Physiol 195:215 –243. doi: 10.1113/jphysiol.1968.sp008455  
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
63 
arXiv:1901.06032 [cs.CV]  
 Ian Goodfellow, Bengio Y, Courvill e A (2017) Deep learning. Nat Methods 13:35. doi: 
10.1038/nmeth.3707  
Ioffe S, Szegedy C (2015) Batch Normalization: Accelerating Deep Network Training by 
Reducing Internal Covariate Shift. doi: 10.1016/j.molstruc.2016.12.061  
Jaderberg M, Simonyan K, Zisser man A, Kavukcuoglu K (2015) Spatial Transformer Networks. 
1–15. doi: 10.1038/nbt.3343  
Jarrett K, Kavukcuoglu K, Ranzato M, LeCun Y (2009) What is the best mu lti-stage architecture 
for object recognition? BT  - Computer Vision, 2009 IEEE 12th International Conference 
on. Comput Vision, 2009 … 2146 –2153  
Ji S, Yang M, Yu K, Xu W (2010) 3D convolutional neural networks for human action 
recognition. ICML, Int Conf Mach Learn 35:221 –31. doi: 10.1109/TPAMI.2012.59  
Joachims T (1998) Text categorization with support  vector machines: Learning with many 
relevant features. In: European conference on machine learning. pp 137 –142 
Justus D, Brennan J, Bonner S, McGough AS (20 19) Predicting the Computational Cost of Deep 
Learning Models. In: Proceedings - 2018 IEEE Internat ional Conference on Big Data, Big 
Data 2018  
Kafi M, Maleki M, Davoodian N (2015) Functional histology of the ovarian follicles as 
determined by follicular fl uid concentrations of steroids and IGF -1 in Camelus dromedarius. 
Res Vet Sci 99:37 –40. doi: 10.1016/j.rvsc.2015.01.001  
Kahng M, Thorat N, Chau DHP, et al (2019) GAN Lab: Understanding Complex Deep 
Generative Models using Interactive Visual Experimentation.  IEEE Trans Vis Comput 
Graph 25:310 –320 
Kalchbrenner N, Grefenstette E, Blunsom P (2014) A c onvolutional neural network for 
modelling sentences. arXiv Prepr arXiv14042188  
Kawaguchi K, Huang J, Kaelbling LP (2019) Effect of depth and width on local minima i n deep 
learning. Neural Comput 31:1462 –1498. doi: 10.1162/neco_a_01195  
Kawashima T, Kawanish i Y, Ide I, et al (2017) Action recognition from extremely low -
resolution thermal image sequence. In: 2017 14th IEEE International Conference on 
Advanced Video and Signal Based Surveillance, AVSS 2017. IEEE, pp 1 –6 
Khan A, Qureshi AS, Hussain M, et al (201 9) A Recent Survey on the Applications of Genetic 
Programming in Image Processing. arXiv Prepr arXiv190107387  
Khan A, Sohail A, Ali A (2018a) A New Channel Boosted Convolutional Neural Network using 
Transfer Learning. arXiv Prepr arXiv180408528  
Khan A, Zam eer A, Jamal T, Raza A (2018b) Deep Belief Networks Based Feature Generation 
and Regression for Predicting Wind Power. arXiv Prepr arXiv180711682  
Krizhevsky A, Suts kever I, Hinton GE (2012) ImageNet Classification with Deep Convolutional 
Neural Networks. A dv Neural Inf Process Syst 1 –9. doi: 10.1061/(ASCE)GT.1943 -
5606.0001284  
Kuen J, Kong X, Wang G, et al (2017) DelugeNets: Deep Networks with Efficient and Flexible 
Cross-layer Information Inflows. In: Computer Vision Workshop (ICCVW), 2017 IEEE 
Internationa l Conference on. pp 958 –966 
Kuen J, Kong X, Wang G, Tan YP (2018) DelugeNets: Deep Networks with Efficient and 
Flexible Cross -Layer Information Inflows. Proc - 2017  IEEE Int Conf Comput Vis Work 
ICCVW 2017 2018 -Janua:958 –966. doi: 10.1109/ICCVW.2017.117  
Lacey G, Taylor GW, Areibi S (2016) Deep Learning on FPGAs: Past, Present, and Future. 
arXiv Prepr arXiv160204283  
Larsson G, Maire M, Shakhnarovich G (2016) Fractalne t: Ultra -deep neural networks without 
residuals. arXiv Prepr arXiv160507648 1 –11 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
64 
arXiv:1901.06032 [cs.CV]  
 Laskar MNU,  Giraldo LGS, Schwartz O (2018) Correspondence of Deep Neural Networks and 
the Brain for Visual Textures. 1 –17 
Le Q V., Ranzato M, Monga R, et al (2011) Building hi gh-level features using large scale 
unsupervised learning. ICASSP, IEEE Int Conf Acoust Spee ch Signal Process - Proc 8595 –
8598. doi: 10.1109/ICASSP.2013.6639343  
LeCun Y (2007) Effcient BackPrp. J Exp Psychol Gen 136:23 –42 
LeCun Y, Bengio Y, Hinton G (2015)  Deep learning. Nature 521:436 –444. doi: 
10.1038/nature14539  
LeCun Y, Boser B, Denker JS, et al (1989) Backpropagation applied to handwritten zip code 
recognition. Neural Comput 1:541 –551 
LeCun Y, Bottou L, Bengio Y, Haffner P (1998) Gradient -based learnin g applied to document 
recognition. Proc IEEE 86:2278 –2324  
LeCun Y, Jackel LD, Bottou L, et  al (1995) Learning algorithms for classification: A comparison 
on handwritten digit recognition. Neural networks Stat Mech Perspect 261:276  
LeCun Y, Kavukcuoglu K, F arabet CC, others (2010) Convolutional networks and applications 
in vision. In: ISCAS. IEE E, pp 253 –256 
Lee C -Y, Gallagher PW, Tu Z (2016) Generalizing pooling functions in convolutional neural 
networks: Mixed, gated, and tree. In: Artificial Intelligence and Statistics. pp 464 –472 
Lee S, Son K, Kim H, Park J (2017) Car Plate Recognition Based on CNN Using Embedded 
System with GPU. 239 –241 
Levi G, Hassner T (2009) Sicherheit und Medien. Sicherheit und Medien. doi: 
10.1109/CVPRW.2015.7301352  
Li H, Lin Z, She n X, et al (2015) A convolutional neural network cascade for face detection. In: 
Proceedin gs of the IEEE Conference on Computer Vision and Pattern Recognition. pp 
5325 –5334  
Li S, Liu Z -Q, Chan AB (2014) Heterogeneous Multi -task Learning for Human Pose Esti mation 
with Deep Convolutional Neural Network. In: 2014 IEEE Conference on Computer Vision  
and Pattern Recognition Workshops. IEEE, pp 488 –495 
Li X, Bing L, Lam W, Shi B (2018) Transformation Networks for Target -Oriented Sentiment 
Classification. 946 –956 
Lin M, Chen Q, Yan S (2013) Network In Network. 1 –10. doi: 10.1109/ASRU.2015.7404828  
Lin T -Y, Maire M, Belongie S, et al (2014) Microsoft coco: Common objects in context. In: 
European conference on computer vision. Springer, pp 740 –755 
Lin TY, Dollár P, Gir shick R, et al (2017) Feature pyramid networks for object detection. In: 
Proceedings - 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 
2017  
Lindholm E, Nickolls J, Oberman S, Montrym J (2008) NVIDIA Tesla: A Unified Graphics and 
Compu ting Architecture. IEEE Micro 28:39 –55. doi: 10.1109/MM.2008.31  
Linnainmaa S (1970) The re presentation of the cumulative rounding error of an algorithm as a 
Taylor expansion of the local rounding errors. Master’s Thesis (in Finnish), Univ Helsinki 
6–7 
Liu C-L, Nakashima K, Sako H, Fujisawa H (2003) Handwritten digit recognition: 
benchmarking of  state-of-the-art techniques. Pattern Recognit 36:2271 –2285  
Liu W, Wang Z, Liu X, et al (2017) A survey of deep neural network architectures and their 
applications. N eurocomputing 234:11 –26. doi: 10.1016/j.neucom.2016.12.038  
Liu X, Deng Z, Yang Y (2019) Re cent progress in semantic image segmentation. Artif Intell Rev 
52:1089 –1106. doi: 10.1007/s10462 -018-9641 -3 
Long J, Shelhamer E, Darrell T (2015) Fully convolutional networks for semantic segmentation. 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
65 
arXiv:1901.06032 [cs.CV]  
 In: 2015 IEEE Conference on Computer Vision and Patter n Recognition (CVPR). IEEE, pp 
3431 –3440  
Long ZM, Guo SQ, Chen GJ, Yin BL (2012) Modeling and simulation for the articulated robotic 
arm test system of the combinatio n drive. 2011 Int Conf Mechatronics Mater Eng ICMME 
2011 151:480 –483. doi: 10.4028/www.sci entific.net/AMM.151.480  
Lowe DG (1999) Object recognition from local scale -invariant features. Proc Seventh IEEE Int 
Conf Comput Vis 1150 –1157 vol.2. doi: 10.1109/ICC V.1999.790410  
Lowe DG (2004) Distinctive image features from scale -invariant keypoints. In t J Comput Vis 
60:91 –110 
Lu H, Li B, Zhu J, et al (2017a) Wound intensity correction and segmentation with convolutional 
neural networks. Concurr Comput Pract Exp 29: e3927  
Lu Z, Pu H, Wang F, et al (2017b) The expressive power of neural networks: A view fr om the 
width. In: Advances in Neural Information Processing Systems. pp 6231 –6239  
Lv E, Wang X, Cheng Y, Yu Q (2019) Deep ensemble network based on multi -path fusion.  Artif 
Intell Rev 52:151 –168. doi: 10.1007/s10462 -019-09708 -5 
Madrazo CF, Heredia I, Lloret L, Marco de Lucas J (2019) Application of a Convolutional 
Neural Network for image classification for the analysis of collisions in High Energy 
Physics. EPJ Web Con f. doi: 10.1051/epjconf/201921406017  
Mao X, Shen C, Yang Y -B (2016) Image restoration  using very deep convolutional encoder -
decoder networks with symmetric skip connections. In: Advances in neural information 
processing systems. pp 2802 –2810  
Marmanis D, We gner JD, Galliani S, et al (2016) Semantic segmentation of aerial images with 
an ense mble of CNNs. ISPRS Ann Photogramm Remote Sens Spat Inf Sci 3:473  
Matsugu M, Mori K, Ishii M, Mitarai Y (2002) Convolutional spiking neural network model for 
robust face d etection. In: Neural Information Processing, 2002. ICONIP’02. Proceedings of 
the 9th International Conference on. pp 660 –664 
Mikolov T, Karafiát M, Burget L, et al (2010) Recurrent neural network based language model. 
In: Eleventh Annual Conference of the International Speech Communication Association  
Misra D (2019) Mish: A Self Regula rized Non -Monotonic Neural Activation Function. arXiv 
Prepr ArXiv 190808681  
Mohamed A, Dahl GE, Hinton G (2012) Acoustic modeling using deep belief networks. IEEE 
Trans Audio,  Speech Lang Process 20:14 –22 
Montufar GF, Pascanu R, Cho K, Bengio Y (2014) On t he number of linear regions of deep 
neural networks. In: Advances in neural information processing systems. pp 2924 –2932  
Moons B, Verhelst M (2017) An energy -efficient precisi on-scalable ConvNet processor in 40 -
nm CMOS. IEEE J Solid -State Circuits 52:903 –914 
Morar A, Moldoveanu F, Gröller E (2012) Image segmentation based on active contours without 
edges. Proc - 2012 IEEE 8th Int Conf Intell Comput Commun Process ICCP 2012 213 –220. 
doi: 10.1109/ICCP.2012.6356188  
Nair V, Hinton GE (2010) Rectified linear uni ts improve Restricted Boltzmann machines. In: 
ICML 2010 - Proceedings, 27th International Conference on Machine Learning  
Najafabadi MM, Villanustre F, Khoshgoftaar TM, et al ( 2015) Deep learning applications and 
challenges in big data analytics. J Big Data  2:1–21. doi: 10.1186/s40537 -014-0007 -7 
Nguyen G, Dlugolinsky S, Bobák M, et al (2019) Machine Learning and Deep Learning 
frameworks and libraries for large -scale data mining:  a survey. Artif Intell Rev 52:77 –124. 
doi: 10.1007/s10462 -018-09679 -z 
Nguyen Q, Mukkamala M, Hein M (2018) Neural Networks Should Be Wide Enough to Learn 
Disconnected Decision Regions. arXiv Prepr arXiv180300094  
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
66 
arXiv:1901.06032 [cs.CV]  
 Nickolls J, Buck I, Garland M, Skadron K (2 008) Scalable parallel programming with CUDA. 
In: ACM SIGGRAPH 2008 classes on - SIGGRAPH ’08. ACM Press, New York, New 
York, USA, p 1  
Nwankpa C, Ijomah W, Gachagan A, Marshall S (2018) Activation Functions: Comparison of 
trends in Practice and Research fo r Deep Learning. arXiv Prepr arXiv181103378  
Oh K -S, Jung K (2004) GPU implementat ion of neural networks. Pattern Recognit 37:1311 –
1314  
Ojala T, PeitiKainen M, Maenpã T (2002) Multiresolution gray -scale and rotation invariant 
texture classification with loc al binary patterns. IEEE Trans Pattern Anal ans Mach Intell  
Ojala T, Pietikäinen M, Harwood D (1996) A comparative study of texture measures with 
classification based on feature distributions. Pattern Recognit 29:51 –59. doi: 10.1016/0031 -
3203(95)00067 -4 
Oquab M, Bottou L, Laptev I, Sivic J (2014) Learning and transferring mid -level ima ge 
representations using convolutional neural networks. In: Proceedings of the IEEE Computer 
Society Conference on Computer Vision and Pattern Recognition. IEEE, pp 1717 –1724  
Pang J, Chen K, Shi J, et al (2020) Libra R -CNN: Towards Balanced Learning for Ob ject 
Detection  
Pascanu R, Mikolov T, Bengio Y (2012) Understanding the exploding gradient problem. CoRR, 
abs/12115063  
Peng X, Hoffman J, Yu SX, Saenko K (2016) Fine -to-coarse knowledge transfer for low -res 
image classification. In: 2016 IEEE International Conference on Image Processing (ICIP). 
IEEE, pp 3683 –3687  
Potluri S, Fasih A, Vutukuru LK, et al (2011) CNN based high performance computing for real 
time image processing on GPU. In: Proceedings of the Joint INDS’11 & ISTET’11. pp 1 –7 
Qiang Yang, Pan SJ, Yang Q, Fellow QY (2008) A Survey on Transfer Learning. IEEE Trans 
Knowl Data Eng 1:1 –15. doi: 10.1109/TKDE.2009.191  
Qureshi AS, Khan A (2018) Adaptive Transfer Learning in De ep Neural Networks: Wind Power 
Prediction using Knowledge Transfer from Region to  Region and Between Different Task 
Domains. arXiv Prepr arXiv181012611  
Qureshi AS, Khan A, Zameer A, Usman A (2017) Wind power prediction using deep neural 
network based meta regression and transfer learning. Appl Soft Comput J 58:742 –755. doi: 
10.1016/j.asoc.2017.05.031  
Ramachandran P, Zoph B, Le Q V. (2017) Swish: a Self -Gated Activation Function. arXiv  
Ranjan R, Patel VM, Chellappa R (2015) A deep pyramid deformable part mod el for face 
detection. arXiv Prepr arXiv150804389  
Ranzato M, Huang FJ,  Boureau YL, LeCun Y (2007) Unsupervised learning of invariant feature 
hierarchies with applications to object recognition. In: Proceedings of the IEEE Computer 
Society Conference on Com puter Vision and Pattern Recognition. IEEE, pp 1 –8 
Rawat W, Wang Z (20 16) Deep Convolutional Neural Networks for Image Classification: A 
Comprehensive Review. 61:1120 –1132. doi: 10.1162/NECO  
Ren S, He K, Girshick R, Sun J (2015) Faster R -CNN: Towards Real -Time Object Detection 
with Region Proposal Networks. 1 –9. doi: 10.1109 /TPAMI.2016.2577031  
Ronneberger O, Fischer P, Brox T (2015) U -net: Convolutional networks for biomedical image 
segmentation. In: Lecture Notes in Computer Science (including subseries Le cture Notes in 
Artificial Intelligence and Lecture Notes in Bioinforma tics) 
Roy AG, Navab N, Wachinger C (2018) Concurrent spatial and channel ‘squeeze & excitation’ 
in fully convolutional networks. Lect Notes Comput Sci (including Subser Lect Notes Artif 
Intell Lect Notes Bioinformatics) 11070 LNCS:421 –429. doi: 10.1007/978 -3-030-00928 -
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
67 
arXiv:1901.06032 [cs.CV]  
 1_48  
Russakovsky O, Deng J, Su H, et al (2015) ImageNet Large Scale Visual Recognition Challenge. 
Int J Comput Vis. doi: 10.1007/s11263 -015-0816 -y 
Salakhutdinov R, Larochell e H (2010) Efficient learning of deep Boltzmann machines. In: 
Proceedi ngs of the thirteenth international conference on artificial intelligence and statistics. 
pp 693 –700 
Scherer D, Müller A, Behnke S (2010) Evaluation of pooling operations in convolutiona l 
architectures for object recognition. In: Artificial Neural Networks --ICANN 2010. Springer, 
pp 92 –101 
Schmidhuber J (2007) New millennium AI and the convergence of history. In: Challenges for 
computational intelligence. Springer, pp 15 –35 
Sermanet P, Chi ntala S, Lecun Y (2012) Convolutional neural networks applied to house  
numbers digit classification. In: Proceedings of the 21st International Conference on Pattern 
Recognition (ICPR2012), Tsukuba. IEEE, pp 3288 –3291  
Shakeel MF, Bajwa NA, Anwaar AM, et al (2019) Detecting Driver Drowsiness in Real Time 
Through Deep Learning Based Object Detection. In: Lecture Notes in Computer Science 
(including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in 
Bioinformatics)  
Sharma A, Muttoo SK (2018 ) Spatial Image Steganalysis Based on ResNeXt. 2018 IEEE 18th 
Int Conf  Commun Technol 1213 –1216. doi: 10.1109/ICCT.2018.8600132  
Shi Y, Tian Y, Wang Y, Huang T (2017) Sequential deep trajectory descriptor for action 
recognition with three -stream CNN. IEEE T rans Multimed 19:1510 –1520  
Shin H -CC, Roth HR, Gao M, et al (2016) Dee p Convolutional Neural Networks for Computer -
Aided Detection: CNN Architectures, Dataset Characteristics and Transfer Learning. IEEE 
Trans Med Imaging 35:1285 –1298. doi: 10.1109/TMI.2016 .2528162  
Simard PY, Steinkraus D, Platt JC (2003) Best practices for c onvolutional neural networks 
applied to visual document analysis. In: null. p 958  
Simonyan K, Vedaldi A, Zisserman A (2013) Deep Inside Convolutional Networks: Visualising 
Image Classifi cation Models and Saliency Maps. 1 –8. doi: 
10.1080/00994480.2000.10748 487 
Simonyan K, Zisserman A (2015) VERY DEEP CONVOLUTIONAL NETWORKS FOR 
LARGE -SCALE IMAGE RECOGNITION. ICLR 75:398 –406. doi: 10.2146/ajhp170251  
Simonyan K, Zisserman A (2014) Two -stream convolutional networks for action recognition in 
videos. In: Advances in neural information processing systems. pp 568 –576 
Sinha T, Verma B, Haidar A (2018) Optimization of convolutional neural network parameters 
for image classification. 2017 IEEE Symp Se r Comput Intell SSCI 2017 - Proc 2018 -
Janua:1 –7. doi: 10.1109/SSCI.201 7.8285338  
Spanhol FA, Oliveira LS, Petitjean C, Heutte L (2016a) A dataset for breast cancer 
histopathological image classification. IEEE Trans Biomed Eng 63:1455 –1462  
Spanhol FA, Olivei ra LS, Petitjean C, Heutte L (2016b) Breast cancer histopathological image 
classification using Convolutional Neural Networks. In: 2016 International Joint 
Conference on Neural Networks (IJCNN). IEEE, pp 2560 –2567  
Srinivas S, Sarvadevabhatla RK, Mopuri KR,  et al (2016) A Taxonomy of Deep Convolutional 
Neur al Nets for Computer Vision. Front Robot AI 2:1 –13. doi: 10.3389/frobt.2015.00036  
Srivastava N, Hinton G, Krizhevsky A, et al (2014) Dropout: A Simple Way to Prevent Neural 
Networks from Overfittin. J Mach  Learn Res 1:11. doi: 10.1016/j.micromeso.2003.09.0 25 
Srivastava RK, Greff K, Schmidhuber J (2015a) Highway Networks. doi: 10.1002/esp.3417  
Srivastava RK, Greff K, Schmidhuber J (2015b) Training very deep networks. In: Advances in 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
68 
arXiv:1901.06032 [cs.CV]  
 Neural Information Proces sing Systems  
Stefanini M, Lancellotti R, Baraldi L, Calderara S (2019) A Deep -learning -based approach to 
VM behavior Identification in Cloud Systems. In: Proceedings of the 9th International 
Conference on Cloud Computing and Services Science. SCITEPRESS - Science and 
Technology Publications, pp 3 08–315 
Strigl D, Kofler K, Podlipnig S (2010) Performance and scalability of GPU -based convolutional 
neural networks. In: Parallel, Distributed and Network -Based Processing (PDP), 2010 18th 
Euromicro International C onference on. pp 317 –324 
Suganuma M, Shir akawa S, Nagao T (2017) A genetic programming approach to designing 
convolutional neural network architectures. In: Proceedings of the Genetic and Evolutionary 
Computation Conference. ACM, pp 497 –504 
Sun L, Jia K, Y eung D -Y, Shi BE (2015) Human action reco gnition using factorized spatio -
temporal convolutional networks. In: Proceedings of the IEEE International Conference on 
Computer Vision. pp 4597 –4605  
Sundermeyer M, Schlüter R, Ney H (2012) LSTM neural networks for  language modeling. In: 
Thirteenth annual  conference of the international speech communication association  
Sze V, Chen YH, Yang TJ, Emer JS (2017) Efficient Processing of Deep Neural Networks: A 
Tutorial and Survey. Proc. IEEE  
Szegedy C, Ioffe S, Vanhoucke  V (2016a) Inception -v4, Inception -ResNet  and the Impact of 
Residual Connections on Learning. arXiv Prepr arXiv160207261v2 131:262 –263. doi: 
10.1007/s10236 -015-0809 -y 
Szegedy C, Vanhoucke V, Ioffe S, et al (2016b) Rethinking the Inception Architecture for 
Computer Vision. In: Proceedings of the I EEE Computer Society Conference on Computer 
Vision and Pattern Recognition. IEEE, pp 2818 –2826  
Szegedy C, Wei Liu, Yangqing Jia, et al (2015) Going deeper with convolutions. In: 2015 IEEE 
Conference on Computer Visi on and Pattern Recognition (CVPR). IEEE, pp 1–9 
Szegedy C, Zaremba W, Sutskever I, et al (2014) Intriguing properties of neural networks. In: 
2nd International Conference on Learning Representations, ICLR 2014 - Conference Track 
Proceedings  
Targ S, Almeida  D, Lyman K (2016) Resnet in Resnet: gene ralizing residual architectures. arXiv 
Prepr arXiv160308029  
Tong T, Li G, Liu X, Gao Q (2017) Image super -resolution using dense skip connections. In: 
2017 IEEE International Conference on Computer Vision (ICCV). pp  4809 –4817  
Tong W, Song L, Yang X, et al (2015) CNN -based shot boundary detection and video 
annotation. In: 2015 IEEE international symposium on broadband multimedia systems and 
broadcasting. IEEE, pp 1 –5 
Tran D, Bourdev L, Fergus R, et al (2015) Learning spatiotemporal features with 3d 
convoluti onal networks. In: Proceedings of the IEEE international conference on computer 
vision. pp 4489 –4497  
Ullah A, Ahmad J, Muhammad K, et al (2017) Action recognition in video sequences using deep 
bi-directional LSTM wi th CNN features. IEEE Access 6:1155 –1166  
Vinayakumar R, Soman KP, Poornachandrany P (2017) Applying convolutional neural network 
for network intrusion detection. In: 2017 International Conference on Advances in 
Computing, Communications and Informatics, IC ACCI 2017  
Vincent P, Larochelle H, Bengio  Y, Manzagol P -A (2008) Extracting and composing robust 
features with denoising autoencoders. In: Proceedings of the 25th international conference 
on Machine learning. ACM, pp 1096 –1103  
Vinyals O, Toshev A, Bengio S , Erhan D (2017) Show and Tell: Lessons L earned from the 2015 
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
69 
arXiv:1901.06032 [cs.CV]  
 MSCOCO Image Captioning Challenge. IEEE Trans Pattern Anal Mach Intell. doi: 
10.1109/TPAMI.2016.2587640  
Wahab N, Khan A, Lee YS (2019) Transfer learning based deep CNN for segmentation and 
detec tion of mitoses in breast cancer histopat hological images. Microscopy 68:216 –233. 
doi: 10.1093/jmicro/dfz002  
Wahab N, Khan A, Lee YS (2017) Two -phase deep convolutional neural network for reducing 
class skewness in histopathological images based breast can cer detection. Comput Biol Med 
85:86 –97. doi: 10.1016/j.compbiomed.2017.04.012  
Wang F, Jiang M, Qian C, et al (2017a) Residual Attention Network for Image Classification. In: 
2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). IEEE, pp 
6450 –6458  
Wang H, Raj B (2017) On the Ori gin of Deep Learning. 1 –72. doi: 10.1016/0014 -
5793(91)81229 -2 
Wang H, Schmid C (2013) Action recognition with improved trajectories. In: Proceedings of the 
IEEE international conference on computer vision. pp 3551 –3558 
Wang T, Wu DJDJ, Coates A, Ng AY (201 2) End -to-end text recognition with convolutional 
neural networks. ICPR, Int Conf Pattern Recognit 3304 –3308  
Wang X, Gao L, Song J, Shen H (2017b) Beyond Frame -level CNN: Saliency -Aware 3 -D CNN 
With LSTM for Video A ction Recognition. IEEE Signal Process Lett 24:510 –514. doi: 
10.1109/LSP.2016.2611485  
Wang Y, Wang L, Wang H, Li P (2019) End -to-End Image Super -Resolution via Deep and 
Shallow Convolutional Networks. IEEE Access 7:31959 –31970. doi: 
10.1109/ACCESS.2019.290 3582  
Woo S, Park J, Lee JY, Kwe on IS (2018) CBAM: Convolutional block attention module. Lect 
Notes Comput Sci (including Subser Lect Notes Artif Intell Lect Notes Bioinformatics) 
11211 LNCS:3 –19. doi: 10.1007/978 -3-030-01234 -2_1 
Wu J, Leng C, Wang Y, et al  (2016) Quantized convolutional  neural networks for mobile 
devices. In: Proceedings of the IEEE Computer Society Conference on Computer Vision 
and Pattern Recognition  
Xie S, Girshick R, Dollar P, et al (2017) Aggregated Residual Transformations for Deep Ne ural 
Networks. In: 2017 IEEE Co nference on Computer Vision and Pattern Recognition 
(CVPR). IEEE, pp 5987 –5995  
Xie W, Zhang C, Zhang Y, et al (2018) An Energy -Efficient FPGA -Based Embedded System for 
CNN Application. In: 2018 IEEE International Conference o n Electron Devices and Solid 
State Circuits (EDSSC). IEEE, pp 1 –2 
Xiong Y, Kim HJ, Hedau V (2019) ANTNets: Mobile Convolutional Neural Networks for 
Resource Efficient Image Classification. arXiv Prepr ArXiv 190403775  
Xu B, Wang N, Chen T, Li M (2015a) Empi rical Evaluation of Rectified A ctivations in 
Convolutional Network. J Foot Ankle Res 1:O22. doi: 10.1186/1757 -1146 -1-S1-O22 
Xu K, Ba J, Kiros R, et al (2015b) Show, attend and tell: Neural image caption generation with 
visual attention. In: International c onference on machine learning. pp 2048 –2057  
Yamada Y, Iwamura M, Kise K (2016) Deep pyramidal residual networks with separated 
stochastic depth. arXiv Prepr arXiv161201230  
Yang J, Xiong W, Li S, Xu C (2019) Learning structured and non -redundant representat ions with 
deep neural networks.  Pattern Recognit 86:224 –235 
Yang S, Luo P, Loy C -C, Tang X (2015) From facial parts responses to face detection: A deep 
learning approach. In: Proceedings of the IEEE International Conference on Computer 
Vision. pp 3676 –3684  
Published in Artificial Intelligence Review , DOI: https://doi.org/10.1007/s10462 -020-09825 -6 
 
70 
arXiv:1901.06032 [cs.CV]  
 Yıldırım Ö, Pławiak P, Tan RS,  Acharya UR (2018) Arrhythmia detection using deep 
convolutional neural network with long duration ECG signals. Comput Biol Med. doi: 
10.1016/j.compbiomed.2018.09.009  
Young SR, Rose DC, Karnowski TP, et al (2015) Optimizing d eep learning hyper -parameters 
through an evolutionary algorithm. In: Proceedings of the Workshop on Machine Learning 
in High -Performance Computing Environments. ACM, p 4  
Zagoruyko S, Komodakis N (2016) Wide Residual Networks. Procedings Br Mach Vis Conf 
2016 87.1 -87.12. doi: 10.5244/C.3 0.87 
Zeiler MD, Fergus R (2013) Visualizing and Understanding Convolutional Networks. arXiv 
Prepr arXiv13112901v3 30:225 –231. doi: 10.1111/j.1475 -4932.1954.tb03086.x  
Zhang K, Zhang Z, Li Z, et al (2016) Joint face detection a nd alignment using multitask 
cascaded convolutional networks. IeeexploreIeeeOrg 23:1499 –1503  
Zhang Q, Zhang M, Chen T, et al (2019) Recent advances in convolutional neural network 
acceleration. Neurocomputing 323:37 –51. doi: 10.1016/j.neucom.2018.09.038  
Zhang X, LeCun Y (201 5) Text understanding from scratch. arXiv Prepr arXiv150201710  
Zhang X, Li Z, Loy CC, Lin D (2017) PolyNet: A Pursuit of Structural Diversity in Very Deep 
Networks. In: 2017 IEEE Conference on Computer Vision and Pattern Recognition 
(CVP R). IEEE, pp 3900 –3908 
Zhang X, Zhou X, Lin M, Sun J (2018a) ShuffleNet: An Extremely Efficient Convolutional 
Neural Network for Mobile Devices. In: Proceedings of the IEEE Computer Society 
Conference on Computer Vision and Pattern Recognition  
Zhang Y, Qiu  Z, Yao T, et al (2 018b) Fully Convolutional Adaptation Networks for Semantic 
Segmentation. In: Proceedings of the IEEE Computer Society Conference on Computer 
Vision and Pattern Recognition  
Zheng H, Fu J, Mei T, Luo J (2017) Learning multi -attention convo lutional neural net work for 
fine-grained image recognition. In: 2017 IEEE International Conference on Computer 
Vision (ICCV). pp 5219 –5227  
Zhou B, Khosla A, Lapedriza A, et al (2016) Learning deep features for discriminative 
localization. In: Proceedings o f the IEEE Conferen ce on Computer Vision and Pattern 
Recognition. pp 2921 –2929  
 
 
 
 
 
  
 
